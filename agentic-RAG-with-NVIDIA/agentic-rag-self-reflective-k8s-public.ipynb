{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95e3951-1a61-4926-b53e-5bf65d89cba5",
   "metadata": {},
   "source": [
    "# Agentic Self-Reflective RAG on Dell AI Factory with NVIDIA\n",
    "### with Elasticsearch vector database\n",
    "### Models served from K8s cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af8c91-1f14-4f64-8d64-4a9781f88066",
   "metadata": {},
   "source": [
    "<img src=\"images/agentic-rag-pipeline.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214c25e-344d-47a4-ac93-423b590f9a9f",
   "metadata": {},
   "source": [
    "## What is Agentic RAG?  \n",
    "\n",
    "LLM agents extend the capabilities of traditional LLMs by blending their natural language comprehension capabilities with actionable functionalities. This is a significant advancement for AI, making it ideal for automation and intelligent decision-making across industries. Unlike traditional LLMs, which generate text based solely on their training data, LLM agents can connect to external systems such as APIs, databases, and applications to fetch live data, provide contextually relevant responses, and combine them in pipelines to enhance their utility in real-world applications.\n",
    "\n",
    "\n",
    "This ability transforms LLMs from passive responders into dynamic actors capable of handling multi-step workflows and delivering actionable insights. In healthcare, for instance, LLM agents can securely synthesize information from patient records, clinical guidelines, and research databases to support timely, evidence-based decisions. These agents can assist in tasks such as patient diagnosis, treatment planning, and drug discovery, thereby enhancing the efficiency and accuracy of healthcare processes.\n",
    "\n",
    "\n",
    "The power to process and act on information in real time while adhering to stringent compliance standards positions LLM agents as powerful tools for addressing complex, data-intensive challenges. The agents redefine what AI can accomplish, providing scalable, secure, and contextually relevant solutions to some of the most demanding problems in modern industries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5be97b",
   "metadata": {},
   "source": [
    "# NVIDIA NIMs\n",
    "\n",
    "The `langchain-nvidia-ai-endpoints` package contains LangChain integrations building applications with models on \n",
    "NVIDIA NIM inference microservice. NIM supports models across domains like chat, embedding, and re-ranking models \n",
    "from the community as well as NVIDIA. These models are optimized by NVIDIA to deliver the best performance on NVIDIA \n",
    "accelerated infrastructure and deployed as a NIM, an easy-to-use, prebuilt containers that deploy anywhere using a single \n",
    "command on NVIDIA accelerated infrastructure.\n",
    "\n",
    "NVIDIA hosted deployments of NIMs are available to test on the [NVIDIA API catalog](https://build.nvidia.com/). After testing, \n",
    "NIMs can be exported from NVIDIAâ€™s API catalog using the NVIDIA AI Enterprise license and run on-premises or in the cloud, \n",
    "giving enterprises ownership and full control of their IP and AI application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae712c52-b454-4523-95e9-7cc51df8d9f8",
   "metadata": {},
   "source": [
    "### About this notebook\n",
    "\n",
    "- Single LLM role play in a multi-agent set of tasks\n",
    "- Two data sources are used, RAG and a web search fall back, but more can be added to the query router.  Route A and B are available.  Route C is shown as an example.\n",
    "- NVIDIA NIMS are installed on a K8s cluster and accessed via API calls\n",
    "- Notebook does not need to be run on a GPU enabled machine, all GPU required services are provided by the K8s cluster.\n",
    "- Features code that can assist with clickable source files\n",
    "- Features a method to turn OFF the Agentic processes to show the different in results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842ceb37-ee74-45da-b666-f12a2d7ccbb2",
   "metadata": {},
   "source": [
    "### Code credit and inspiration:\n",
    "- https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_self_rag/#llms\n",
    "- https://github.com/NVIDIA/workbench-example-agentic-rag\n",
    "- David O'Dell\n",
    "- Tiffany Fahmy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d304f-dde1-45ed-9c86-eb45de74586b",
   "metadata": {},
   "source": [
    "# Library installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653986bb-82d7-4927-8032-f97771c9a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q langchain-nvidia-ai-endpoints==0.2.2\n",
    "# %pip install -q langchain==0.2.16\n",
    "# %pip install -q langchain-community==0.2.17                   \n",
    "# %pip install -q langchain-core==0.2.40\n",
    "# %pip install -q langchain-text-splitters==0.2.4\n",
    "# %pip install -q langchain-openai==0.1.23\n",
    "# %pip install -q pdfminer-six==20231228\n",
    "# %pip install -q pillow-heif==0.18.0\n",
    "# %pip install -q opencv-python==4.10.0.84 \n",
    "# %pip install -q unstructured==0.15.9\n",
    "# %pip install -q unstructured-pytesseract==0.3.12\n",
    "# %pip install -q pi-heif==0.18.0\n",
    "# %pip install -q unstructured-inference==0.7.36\n",
    "# %pip install -q tesseract==0.1.3\n",
    "# %pip install -q pytesseract==0.3.10\n",
    "# %pip install -q langgraph==0.2.15\n",
    "# %pip install -q gradio==4.27.0\n",
    "# %pip install -q elasticsearch==8.15.1\n",
    "# %pip install -q tiktoken==0.8.0\n",
    "# %pip install -q langchain-elasticsearch==0.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd2cb4-19b9-4f91-b77e-9f64f799a7cf",
   "metadata": {},
   "source": [
    "### Set debug and verbosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993a804c-9ec1-464e-9875-201a30aaa40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "# set_debug(True)\n",
    "# set_verbose(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac01f3-238c-42da-92be-ed54adb5e591",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2ffb6b-813b-47a7-82d9-62001adc3c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.1\n"
     ]
    }
   ],
   "source": [
    "import nltk  \n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f7bc58-8680-418e-8279-af8715bd3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import loaders\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import CSVLoader\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_community.document_loaders import OnlinePDFLoader\n",
    "from langchain_community.document_loaders.merge import MergedDataLoader\n",
    "\n",
    "### for embedding\n",
    "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "\n",
    "### status bars and UI and other accessories\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650977f5-c202-4aa7-bde3-212c94c86448",
   "metadata": {},
   "source": [
    "# Declare external services\n",
    "\n",
    "Services that will be hosted outside this application, usually the LLM, the vectordb and anything else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df82fc3-d5cc-4984-8b82-43114bbb8bb5",
   "metadata": {},
   "source": [
    "## Langsmith Tracing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c177e7-0f84-464f-946b-a1ba74988b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "### Consider adding these as env vars in AI Workbench to enable LangSmith tracing ###\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"YOUR PROJECT NAME\"\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"YOUR API KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7154b39-4fdc-4a18-a48f-add9403c9fd2",
   "metadata": {},
   "source": [
    "### Define Local LLM for initial testing\n",
    "\n",
    "##### Model NIM, Embeddingn and Rerank will all have different ports.  In this case we used 30001, 30002, 30003. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b471ddc3-bd98-429e-80db-0f217604af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, NVIDIARerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms import VLLM\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a677f0-b851-4fce-a0cd-a1a9185992cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta/llama-3.1-8b-instruct\"\n",
    "api_url = \"http://YOUR MODEL SERVER AND PORT/v1\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=api_url,\n",
    "    api_key=\"YOUR API KEY\",\n",
    "    model=model_id,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c23c53-6a15-4f0c-8cd6-d58f4d6943e0",
   "metadata": {},
   "source": [
    "### Define embeddings options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4142ec38-5c75-41a6-9ba6-ba68ee8bf3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = NVIDIAEmbeddings(\n",
    "    base_url=\"http://YOUR MODEL SERVER AND PORT/v1\", \n",
    "    model=\"nvidia/nv-embedqa-e5-v5\",\n",
    "    truncate=\"END\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f39e5bf-56ad-4fee-823e-d57e3b552a34",
   "metadata": {},
   "source": [
    "### Define reranking options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d6cefce-2f02-4885-a964-318820e3674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = NVIDIARerank(\n",
    "    base_url=\"YOUR MODEL SERVER AND PORT/v1\", \n",
    "    model=\"nvidia/nv-rerankqa-mistral-4b-v3\",\n",
    "    truncate=\"END\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dc6a7c-7ffd-40dd-856f-529ac60f2460",
   "metadata": {},
   "source": [
    "## Define Elasticsearch vector db instance\n",
    "\n",
    "using this as inspiration:  https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/generative-ai/chatbot.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d9f894c-a2fb-4011-a016-8a389e22b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from langchain_elasticsearch import ElasticsearchStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97396109-3f84-426f-8ed1-bea006cb5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set certificate permissions to 644"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3ac5b0-50f6-48fd-a8d4-d4e336bd8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "CERTIFICATE = \"/home/demo/es_http_ca.crt\"\n",
    "HOST = \"https://localhost:9200\"\n",
    "USER = \"elastic\"\n",
    "PASSWORD = \"PASSWORD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ec2b08b-b34e-47ba-a6e2-e918b69294b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch(\n",
    "    hosts=HOST,\n",
    "    basic_auth=(USER, PASSWORD),\n",
    "    verify_certs=True,\n",
    "    ca_certs=CERTIFICATE,\n",
    "    # verify_certs=False,\n",
    "    # ca_certs=False,\n",
    "    # ca_certs=True,    \n",
    "    # connection_class=RequestsHttpConnection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c41fc3-0892-4bdf-89f7-66749e2605ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<Elasticsearch(['https://localhost:9200'])>\n",
      "{'name': '0a7b0a930bd9', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'Xq58NyVaSeq80WPUT2CTpg', 'version': {'number': '8.15.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'f97532e680b555c3a05e73a74c28afb666923018', 'build_date': '2024-10-09T22:08:00.328917561Z', 'build_snapshot': False, 'lucene_version': '9.11.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(es_client.ping())\n",
    "print(es_client)\n",
    "print(es_client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b263cf-798e-49dd-8249-745af64cf7a9",
   "metadata": {},
   "source": [
    "# Vector db Content setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f81069-4f5b-4e40-ba5a-cf27f6c18039",
   "metadata": {},
   "source": [
    "### Load PDF data into loader object\n",
    "\n",
    "##### We want the pdf files to be clickable so we set up a prefix appended to each file that points to the server they are residing at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a411985f-9911-491c-9b50-5c89e5b3d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing PDF files\n",
    "pdf_directory = \"docs/pdf-powerscale-mount\"\n",
    "url_prefix = \"http://IP ADDRESS OF FILE SERVER/\"\n",
    "\n",
    "# Load PDF documents\n",
    "pdf_dir_loader = PyPDFDirectoryLoader(pdf_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cfbb65-a495-442d-88f1-8d0853917096",
   "metadata": {},
   "source": [
    "### Load CSV data into loader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1ea245-e5b6-4c4f-9411-4c49f5f961cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_csv_loader = CSVLoader(\"docs/csv-powerscale-mount/healthcare.csv\", encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381133d5-246c-4090-adc5-6ff830cfa474",
   "metadata": {},
   "source": [
    "### view CSV head contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44eac0cc-a7c1-4f49-a4fa-601b1de9f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d359ac38-62d7-4052-b911-31f6947319ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient Name Date of Birth  Age Reason for Admission       Procedure  \\\n",
      "0    Patient_3      8/6/2004   19                COVID  antiviral meds   \n",
      "1   Patient_39     3/19/2004   19                COVID  oxygen therapy   \n",
      "2   Patient_33     12/8/2002   21                COVID  oxygen therapy   \n",
      "3   Patient_40      7/6/2001   23                  Flu  antiviral meds   \n",
      "4    Patient_1    10/28/1999   24            Pneumonia     antibiotics   \n",
      "\n",
      "       Room Date of Discharge  Length of Stay   Charges  Balance Remaining  \\\n",
      "0  Room_237        12/27/2023               0    237.34              37.34   \n",
      "1  Room_440         1/12/2024              22  29980.84            3018.84   \n",
      "2  Room_298        12/31/2023               6   4028.77            2681.26   \n",
      "3  Room_360        11/30/2023               0    273.69               0.00   \n",
      "4  Room_239          1/5/2024               1    490.50             341.28   \n",
      "\n",
      "   Unnamed: 10  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('docs/csv-powerscale-mount/healthcare.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16048f4e-3fa8-4ffc-a012-ea80772f5687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 50\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "print(f\"Total number of rows: {num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8bff09-ab2b-4fec-b409-c6a0894536d4",
   "metadata": {},
   "source": [
    "## merge pdf and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "943737aa-fc12-4004-b20a-36a433ad47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "# Merge the PDF and CSV loaders into a single dataset\n",
    "merged_loader = MergedDataLoader(loaders=[pdf_dir_loader, patient_data_csv_loader])\n",
    "\n",
    "# Load all the merged documents\n",
    "merged_documents = merged_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc391d19-092d-4b6a-93a7-34027c8c1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(merged_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da8b7e9c-045b-474e-a72d-cda810298ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CSV file rows are broken down and made into one document per row\n",
    "### 230 PDf file documents, + 50 rows of CSV file = 280 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8aecfb9-776e-476f-b020-e98c7ffb50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda77e48-52b5-47a7-9634-13014096f2e3",
   "metadata": {},
   "source": [
    "## Transform source format to include URL for pdf chunks in documents \n",
    "This assumes an nginx instance running and pointing to a mounted pdf directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b21b4714-1d50-442d-a7c9-0b376764b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF documents: 230\n",
      "Total CSV rows: 50\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n"
     ]
    }
   ],
   "source": [
    "# Prepend URL prefix to the source in metadata\n",
    "\n",
    "pdf_count = 0\n",
    "csv_count = 0\n",
    "\n",
    "for doc in merged_documents:\n",
    "    if 'source' in doc.metadata:\n",
    "        # Remove the directory part from the source path\n",
    "        file_name = doc.metadata['source'].replace(pdf_directory + \"/docs\", \"\")\n",
    "        doc.metadata['source'] = url_prefix + file_name\n",
    "\n",
    "        # Count the number of PDF and CSV documents\n",
    "        if file_name.lower().endswith('.pdf'):\n",
    "            pdf_count += 1\n",
    "        elif file_name.lower().endswith('.csv'):\n",
    "            csv_count += 1\n",
    "\n",
    "# Print the total number of PDF and CSV documents\n",
    "print(f\"Total PDF documents: {pdf_count}\")\n",
    "print(f\"Total CSV rows: {csv_count}\")\n",
    "\n",
    "\n",
    "# Print the updated sources to verify\n",
    "for doc in merged_documents[:5]:  # Print first 5 for verification\n",
    "    print(doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fa53c-d634-42a0-aa3a-703af8ed096b",
   "metadata": {},
   "source": [
    "### Chunk and split documents\n",
    "\n",
    "Each document will be chunked and split along the chunk_size parameter.  The overlap parameter will ADD to the amount of characters, so 512 plus 256 overlap will equal a split size of around 800.  An overlap of zero will equal a split size of only the chunk value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52cb147e-2332-42b3-9ae9-0b873e606651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=512, chunk_overlap=64)\n",
    "doc_splits = text_splitter.split_documents(merged_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1eb94-f0aa-4a1b-ac79-4af35f21c3ac",
   "metadata": {},
   "source": [
    "## Prepare Elasticsearch Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8577cbb-dd76-431d-af61-d1d706693224",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"merged_chunked_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99253b-15f8-4a83-ba1a-82e02b441e72",
   "metadata": {},
   "source": [
    "### Delete and rebuild ES index\n",
    "\n",
    "NOTE:  If you don't delete the index and start embedding duplicates into an existing index, you will get extremely bad performance and errors due to mulitiple documents with the same content.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c34a399-4ac5-4ab2-bb61-69e191f9bd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'merged_chunked_index' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Check if the index exists and delete it if it does\n",
    "if es_client.indices.exists(index=INDEX_NAME):\n",
    "    es_client.indices.delete(index=INDEX_NAME)\n",
    "    print(f\"Index '{INDEX_NAME}' deleted successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' does not exist, will be created in the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73db8d-f62c-4609-8758-c906a121b188",
   "metadata": {},
   "source": [
    "### Initial embed documents into vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dfb4b48-437d-4f20-928b-51ce9ad171c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to complete:\n",
      "CPU times: user 376 ms, sys: 31.8 ms, total: 408 ms\n",
      "Wall time: 3.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorstore = ElasticsearchStore.from_documents(\n",
    "    doc_splits,\n",
    "    embeddings,\n",
    "    index_name=INDEX_NAME,\n",
    "    es_connection=es_client,\n",
    ")\n",
    "\n",
    "print('\\n' + 'Time to complete:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3f4db-e530-4a8e-82e1-c4d09e3295f0",
   "metadata": {},
   "source": [
    "### Verify document structure in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80be3e9c-3f7f-4033-b211-8a2779909c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to check the structure of documents in the index\n",
    "# def check_document_structure(index_name, es_client, num_docs=2):\n",
    "#     # Search for documents in the index\n",
    "#     response = es_client.search(\n",
    "#         index=index_name,\n",
    "#         body={\n",
    "#             \"query\": {\n",
    "#                 \"match_all\": {}\n",
    "#             },\n",
    "#             \"size\": num_docs\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     # Check if documents are found\n",
    "#     if response['hits']['total']['value'] > 0:\n",
    "#         print(f\"Found {response['hits']['total']['value']} documents in the index '{index_name}'.\")\n",
    "#         for doc in response['hits']['hits']:\n",
    "#             print(f\"Document ID: {doc['_id']}\")\n",
    "#             print(f\"Document structure: {doc['_source']}\")\n",
    "#             print(\"-\" * 80)\n",
    "#     else:\n",
    "#         print(f\"No documents found in the index '{index_name}'.\")\n",
    "\n",
    "# # Check the structure of documents\n",
    "# check_document_structure(INDEX_NAME, es_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d7244c-b979-480e-9f24-38a89ddd3a64",
   "metadata": {},
   "source": [
    "### Create direct vectorstore retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12287fcf-e8d9-4b8f-a445-8792d1b63ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2c61fa-54ef-4eec-81e9-1da7c1cd9d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_unique_files(merged_documents):\n",
    "    file_list = []\n",
    "    \n",
    "    for doc in merged_documents:\n",
    "        source = doc.metadata.get('source', None)\n",
    "        if source:\n",
    "            file_list.append(source)\n",
    "    \n",
    "    # Use a set to get unique file URLs\n",
    "    unique_list = list(set(file_list))\n",
    "    \n",
    "    # Sort the unique list by file extension\n",
    "    sorted_unique_list = sorted(unique_list, key=lambda x: x.split('.')[-1])\n",
    "    \n",
    "    print(\"\\nList of unique files in merged loader, sorted by file type:\\n\")\n",
    "    for unique_file in sorted_unique_list:\n",
    "        print(unique_file)\n",
    "    \n",
    "    pretty_files = json.dumps(sorted_unique_list, indent=4, default=str)\n",
    "    \n",
    "    return pretty_files\n",
    "\n",
    "# Example usage\n",
    "unique_files_sorted = get_unique_files(merged_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d438f1-9de0-4531-825d-c8a008f3119b",
   "metadata": {},
   "source": [
    "# Setup and Test Agent pipeline elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39d22c-a5f1-4f89-b053-48b22483e8c8",
   "metadata": {},
   "source": [
    "### Generate RAG Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d531a81-6d4d-405e-975a-01ef1c9679fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant in a health care clinic. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Please keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "question = \"Tell me about mental health from a population perspective.\"\n",
    "docs = retriever.invoke(question)\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "372c83d1-47ad-4ab0-b1d3-61f061d44b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc2a38d-5526-40c2-9618-465a710d0d98",
   "metadata": {},
   "source": [
    "### RAG only function for Basic RAG toggle\n",
    "\n",
    "Grab the response and source doc name and a snippet of content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84accb68-ce9a-4783-94e3-3983e084175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_response(question):\n",
    "    docs = retriever.invoke(question)\n",
    "    generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    \n",
    "\n",
    "    basic_rag_formatted_output_source_docs = []\n",
    "\n",
    "    base_url = 'http://172.16.6.3'\n",
    "\n",
    "    thumbnail_path = 'images/thumbnails/folder-icon.jpg'\n",
    "    \n",
    "    for doc in docs:\n",
    "        source = doc.metadata['source']  # Assuming 'metadata' is a dictionary with a 'source' key\n",
    "        page_content_snippet = doc.page_content[:200]  # Get the first x number of characters of the snippet\n",
    "        \n",
    "        # Append the formatted HTML to the list\n",
    "        basic_rag_formatted_output_source_docs.append(f'''\n",
    "        <base href=\"{base_url}\">\n",
    "\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td>\n",
    "                <!-- <img src=\"{thumbnail_path}\" alt=\"Thumbnail\" style=\"width:100px;height:auto;\"> -->\n",
    "                \n",
    "                <img src=\"{thumbnail_path}\" alt=\"Thumbnail\" style=\"width:auto;height:auto;\">\n",
    "\n",
    "                </td>\n",
    "                <td>\n",
    "                    <a href=\"{source}\" target=\"_blank\" class=\"custom-link\">{source}</a><br>\n",
    "                    Snippet: {page_content_snippet}<br><br>\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        ''')\n",
    "\n",
    "    # Combine the generation and formatted output into a single output\n",
    "    return generation, basic_rag_formatted_output_source_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61db24-79d2-4bcf-96a1-ae5f7a9f18f9",
   "metadata": {},
   "source": [
    "### Question Router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c910c1-738c-4bf7-bf9e-801862b227eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore exclusively for questions related to patient data, skin cancer, covid, or mental health. \n",
    "    You do not need to be stringent with keywords in the question related to these topics. If **any document** is found to be relevant in the vectorstore, stop immediately and generate the answer using that data. \n",
    "    **Do not perform a web search** if even one relevant document is found, regardless of the overall assessment of other documents.\n",
    "    If **no relevant data** is found at all in the vectorstore, or if the question is unrelated to these topics, use web_search.\n",
    "    \n",
    "    Provide the answer in JSON format with a single key called 'datasource' and a single answer either 'vectorstore' or 'websearch' as the value.\n",
    "    Please do not include a preamble or explanation. Your response should be formatted as follows: \\'{{\"datasource\": \"value\"}}\\'.\n",
    "\n",
    "    Example 1: A question that is not related to patient data, skin cancer, covid, or mental health should return with a response to use the web_search like this: \\'{{\"datasource\": \"websearch\"}}\\'.\n",
    "\n",
    "    Example 2: A question that is related to patient data, skin cancer, covid, or mental health and any relevant data is found in the vectorstore should return a response like this: \\'{{\"datasource\": \"vectorstore\"}}\\'.\n",
    "\n",
    "    Question to route: {question}\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "question_router = prompt | llm | JsonOutputParser()\n",
    "question = \"Tell me about mental health from a population perspective.\"\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "doc_txt = docs[1].page_content\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "375d0cac-a460-425f-ab14-6f4e45dacb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_rag_response(\"Tell me about mental health from a population perspective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb0d21f-907d-4ab7-9238-bce2437bfa9d",
   "metadata": {},
   "source": [
    "### Relevance / Retrieval Grader\n",
    "\n",
    "Checks index of vectorstore to see if there are relavent docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b008df98-8394-49da-8fb8-aefe2c90d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"Tell me about mental health from a population perspective.\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7446f-1aff-4081-9713-1bc9546f3164",
   "metadata": {},
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "Checks to see if the generation is grounded in truth using the source documents as a reference.  \n",
    "If the generation is grounded in truth, then the hallucination grader responds positively with Yes.\n",
    "\n",
    "If the generation is NOT grounded in truth and has no relavence with the source documents, the grader responds negatively with No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0261a9a4-de13-4dd8-b082-95305a3e43ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score in JSON format with a \n",
    "    single key 'score' and no preamble or explanation, like this \\'{{\\'\"score\": \"yes\"\\'{{\\' or \\'{{\\'\"score\": \"no\"\\'{{\\'. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d1d7b-a23d-4dac-94e2-76960192372d",
   "metadata": {},
   "source": [
    "### Answer Grader\n",
    "\n",
    "Is the answer provided \"useful\" to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df9f6944-4fee-4971-b3a7-2b81b44ed433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score in JSON format with a \n",
    "    single key 'score' and no preamble or explanation, like this \\'{{\\'\"score\": \"yes\"\\'{{\\' or \\'{{\\'\"score\": \"no\"\\'{{\\'. \n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43a82d-9718-4c64-8460-00ba3bd0f59f",
   "metadata": {},
   "source": [
    "### Web Search\n",
    "\n",
    "uses the python library for Tavily open search.  Create an account and API here:\n",
    "https://blog.tavily.com/getting-started-with-the-tavily-search-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edb4e751-9e81-4233-8b94-b066dbd838c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = \"YOUR API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "023ff2db-eb4e-4d44-904c-ea061abc16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e023ee-4f63-4ade-8b47-aebe394e89f6",
   "metadata": {},
   "source": [
    "# Langgraph Node Functions Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a142182-af08-4dea-9245-2922d7c37b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "################################ State ##############################\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        web_search: whether to add internet search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search: str\n",
    "    documents: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26d75d48-fa85-4d85-849a-b6efddb67761",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Nodes ##############################\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ROUTE QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "\n",
    "    ## source here refers to which datasource to route to, RAG or web or other\n",
    "    # Status message\n",
    "    global router_status, router_choice\n",
    "    \n",
    "    target_source = question_router.invoke({\"question\": question})\n",
    "    print(target_source)\n",
    "    \n",
    "    # Check if source is a dictionary\n",
    "    if isinstance(target_source, dict):\n",
    "        if \"datasource\" in target_source:\n",
    "            print(target_source[\"datasource\"])\n",
    "            router_choice = target_source[\"datasource\"]\n",
    "            if target_source[\"datasource\"] == \"websearch\":\n",
    "                print(\"---DECISION: ROUTE QUESTION TO WEB SEARCH---\")\n",
    "                router_status = \"success\"\n",
    "                return \"websearch\"\n",
    "            elif target_source[\"datasource\"] == \"vectorstore\":\n",
    "                print(\"---DECISION: ROUTE QUESTION TO RAG---\")\n",
    "                router_status = \"success\"\n",
    "                return \"vectorstore\"\n",
    "        else:\n",
    "            print(\"Error: 'datasource' key not found in source\")\n",
    "    else:\n",
    "        print(\"Error: source is not a dictionary\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9af52c28-a040-40fe-b61c-f4865b3464df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE USING NVIDIA EMBEDDINGS NIM---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    # Status message\n",
    "    global retrieve_status\n",
    "    retrieve_status = \"success\"\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56743880-d070-4ce1-9587-d841bce6cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---NVIDIA RERANK NIM PROCESS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Reranking\n",
    "    documents = reranker.compress_documents(query=question, documents=documents)\n",
    "\n",
    "    # Status message\n",
    "    global rerank_status\n",
    "    rerank_status = \"success\"\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6beee6e9-8712-4c62-900e-d5e1672ead7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    If no document is relevant, we will set a flag to run web search.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    \n",
    "    global filtered_docs  # Declare the global variable to place docs in to be accessed in other functions\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "\n",
    "    web_search = \"Yes\"  # Default to Yes in case there is no relevant doc\n",
    "\n",
    "    ## take the page content value of documents retrieved and grade it against the question,\n",
    "    ## this means the filtered_docs array will only contain page content values, not file names\n",
    "    \n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        print(grade)\n",
    "        \n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "            # Since we found at least one relevant document, set web_search to \"No\"\n",
    "            web_search = \"No\"\n",
    "            \n",
    "        # Document not relevant\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            # Do not include the document in filtered_docs\n",
    "            # will default to web search = yes\n",
    "            continue\n",
    "\n",
    "    # Status message\n",
    "    global relevance_status\n",
    "    relevance_status = \"success\"\n",
    "    \n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb07cd5b-9276-43e2-925c-b28e2263b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    global web_fallback_status\n",
    "    \n",
    "    if web_search == \"Yes\":\n",
    "        # No relevant documents were found, so fall back to web search\n",
    "        print(\n",
    "            \"---DECISION: RAG DOCS DO NOT CONTAIN RELEVANT CONTENT, FALLING BACK TO WEBSEARCH---\"\n",
    "        )\n",
    "        web_fallback_status = \"success\"\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate the answer\n",
    "        print(\"---DECISION: GENERATE ANSWER---\")\n",
    "        return \"generate\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd3dd6ba-1f10-43be-b34c-19616157d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Check if 'documents' key exists in state, if not, initialize it\n",
    "    if \"documents\" not in state:\n",
    "        state[\"documents\"] = []\n",
    "\n",
    "    ## passes existing documents list to function, there may or may not be doc in the array\n",
    "    \n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "    # Transform the keys from 'url' to 'source' and 'content' to 'page_content'\n",
    "    transformed_docs = [{\"source\": d[\"url\"], \"page_content\": d[\"content\"]} for d in docs]\n",
    "\n",
    "    # Create Document objects with the transformed results\n",
    "    for doc in transformed_docs:\n",
    "        document = Document(metadata={'source': doc['source']}, page_content=doc['page_content'])\n",
    "        documents.append(document)\n",
    "\n",
    "\n",
    "    # # Join the transformed documents into a single string\n",
    "    # web_results = \"\\n\".join([f\"source: {d['source']}\\npage_content: {d['page_content']}\" for d in transformed_docs])\n",
    "\n",
    "    # web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    # web_results = Document(page_content=web_results)\n",
    "\n",
    "    ## adds the web results to the existing documents list\n",
    "    \n",
    "    # documents.append(web_results)\n",
    "\n",
    "    # Status message\n",
    "    global websearch_status\n",
    "    websearch_status = \"success\"\n",
    "    \n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6988645c-4858-4a65-8d61-1322789bc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE AN ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07fa3d08-6a86-4705-a28b-e2721070bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Conditional Edge ##############################\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---HALLUCINATION CHECKER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "\n",
    "    ## SOURCE DOCUMENTS HANDLER ##\n",
    "    ## create a new array with source file and page content snippet for use in GUI output\n",
    "    \n",
    "    global filtered_docs_formatted\n",
    "    filtered_docs_formatted = []\n",
    "\n",
    "    # for doc in documents:\n",
    "    #     source = doc.metadata['source']  # Assuming 'metadata' is a dictionary with a 'source' key\n",
    "    #     page_content_snippet = doc.page_content[:200]  # Get the first x number of characters of the snippet\n",
    "    #     # filtered_docs_formatted.append(f\"Source Document: {source}\\n\\nSnippet: {page_content_snippet}\\n\")\n",
    "\n",
    "    #     ## this will be rendered in gradio as HTML with clickable source if URL\n",
    "    #     filtered_docs_formatted.append(f'Source Document: <a href=\"{source}\" target=\"_blank\" class=\"custom-link\">{source}</a>\\n\\n<br>Snippet: {page_content_snippet}<br><br>\\n')\n",
    "\n",
    "    base_url = 'http://172.16.6.3'\n",
    "\n",
    "    thumbnail_path = 'images/thumbnails/folder-icon.jpg'\n",
    "    \n",
    "    for doc in documents:\n",
    "        source = doc.metadata['source']  # Assuming 'metadata' is a dictionary with a 'source' key\n",
    "        page_content_snippet = doc.page_content[:200]  # Get the first x number of characters of the snippet\n",
    "        \n",
    "        # Append the formatted HTML to the list\n",
    "        filtered_docs_formatted.append(f'''\n",
    "        <base href=\"{base_url}\">\n",
    "\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td>\n",
    "                <!-- <img src=\"{thumbnail_path}\" alt=\"Thumbnail\" style=\"width:100px;height:auto;\"> -->\n",
    "                \n",
    "                <img src=\"{thumbnail_path}\" alt=\"Thumbnail\" style=\"width:auto;height:auto;\">\n",
    "\n",
    "                </td>\n",
    "                <td>\n",
    "                    <a href=\"{source}\" target=\"_blank\" class=\"custom-link\">{source}</a><br>\n",
    "                    Snippet: {page_content_snippet}<br><br>\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        ''')\n",
    "\n",
    "\n",
    "    ### execute hallucination grader function, \n",
    "    ### a grade of YES means grounded in documents.  \n",
    "    ### a grade of NO would indicate not grounded in docs and would qualify as an hallucination.\n",
    "    \n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score[\"score\"]\n",
    "\n",
    "\n",
    "    # Status message\n",
    "    global hallucination_status, usefulness_status\n",
    "\n",
    "\n",
    "    # Check whether or not it passed the hallucination check, yes is pass, no is fail.\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: ANSWER IS GROUNDED IN DOCUMENTS - NO HALLUCINATIONS---\")\n",
    "\n",
    "        hallucination_status = \"success\"\n",
    "\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE ANSWER vs THE QUESTION---\")\n",
    "        \n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score[\"score\"]\n",
    "\n",
    "        ##  check whether or not the answer is related to the question\n",
    "        \n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: ANSWER ADDRESSES QUESTION AND IS USEFUL---\")\n",
    "            usefulness_status = \"success\"\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: ANSWER DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "\n",
    "    ## if it's hallucinating, and answer is not related to documents, retry\n",
    "    else:\n",
    "        print(\"---DECISION: POSSIBLE HALLUCINATIONS - ANSWER IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b1f20fc-12b2-4bfd-b551-779689e382c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "\n",
    "workflow.add_node(\"websearch\", web_search)  # web search\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"rerank\", rerank)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f21594-00d4-48a8-ae2e-4e55a010b540",
   "metadata": {},
   "source": [
    "# Langgraph Graph Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9a4b9e4-3ba8-47d6-958c-e5a7112ac6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"retrieve\", \"rerank\")\n",
    "workflow.add_edge(\"rerank\", \"grade_documents\")\n",
    "\n",
    "# workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"websearch\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55cac61-9150-4b37-b0e4-854f4552d103",
   "metadata": {},
   "source": [
    "# Display graph of node and edge logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13951283-27ae-4f0f-932c-b4fe74419df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "# app = workflow.compile()\n",
    "\n",
    "# display(\n",
    "#     Image(\n",
    "#         app.get_graph().draw_mermaid_png(\n",
    "#             draw_method=MermaidDrawMethod.API\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ed3f4-53bf-40ad-bcb0-0c204ffe0bc7",
   "metadata": {},
   "source": [
    "# Test Question Answer set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13043b0f-17c7-49d3-9ea7-8f2c0f0c8691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Compile\n",
    "# app = workflow.compile()\n",
    "\n",
    "# # Test\n",
    "# from pprint import pprint\n",
    "\n",
    "# inputs = {\"question\": \"Tell me about mental health and include any web search you need to add additional info.\"}\n",
    "# inputs = {\"question\": \"What methods could be used to treat covid in an older patient?\"}\n",
    "# inputs = {\"question\": \"What year did the Bears football team win the super bowl?\"}\n",
    "\n",
    "# for output in app.stream(inputs):\n",
    "#     for key, value in output.items():\n",
    "#         pprint(f\"Finished running: {key}:\")\n",
    "# pprint(value[\"generation\"])\n",
    "\n",
    "# print('\\n' + 'Time to complete:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a48312-b55c-479c-b4ee-d0f4c413b07e",
   "metadata": {},
   "source": [
    "# Agentic Response Function for GUI\n",
    "Adding a bit of formatting as well for the status panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1261f0be-7afe-4b7a-9b35-c3fa88c6d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import time\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "\n",
    "### used to format and color the status alert\n",
    "\n",
    "def status_update(status):\n",
    "    if status == \"success\":\n",
    "        return '<div style=\"background-color: green; color: white; padding: 5px; border-radius: 5px;\">Completed successfully</div>'\n",
    "    elif status in [\"websearch\", \"vectorstore\"]:\n",
    "        return f'<div style=\"background-color: blue; color: white; padding: 5px; border-radius: 5px;\">{status}</div>'\n",
    "    else:\n",
    "        return '<div style=\"background-color: grey; color: white; padding: 5px; border-radius: 5px;\">Not used</div>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "863fbb02-fd75-40aa-8560-88e8e78adff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### MAIN AGENTIC AGGREGATION FUNCTION\n",
    "\n",
    "def get_agentic_response(question, basic_rag_toggle):\n",
    "\n",
    "    ### reset value of previous variable values upon new execution of main function\n",
    "    \n",
    "    global router_status, router_choice, retrieve_status, rerank_status, relevance_status, web_fallback_status, websearch_status, hallucination_status, usefulness_status\n",
    "    \n",
    "    router_status = None\n",
    "    router_choice = None\n",
    "    retrieve_status = None\n",
    "    rerank_status = None\n",
    "    relevance_status = None\n",
    "    web_fallback_status = None\n",
    "    websearch_status = None\n",
    "    hallucination_status = None\n",
    "    usefulness_status = None\n",
    "\n",
    "    # set the globals so that the previous calls to variables can use selected value in this function\n",
    "    global filtered_docs_formatted\n",
    "\n",
    "\n",
    "    model_id = \"meta/llama-3.1-8b-instruct\"\n",
    "    \n",
    "    # Compile the workflow\n",
    "    app = workflow.compile()\n",
    "\n",
    "    # Prepare the input\n",
    "    inputs = {\"question\": question}\n",
    "\n",
    "    # Initialize the response variable\n",
    "    response = None\n",
    "\n",
    "    # Create a string buffer to capture print statements\n",
    "    buffer = io.StringIO()\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Stream the output from the app\n",
    "    with redirect_stdout(buffer):\n",
    "        for output in app.stream(inputs):\n",
    "            for key, value in output.items():\n",
    "                # Check if 'generation' key is in the value\n",
    "                if 'generation' in value:\n",
    "                    response = value['generation']\n",
    "\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the total processing time\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # Get the captured print statements\n",
    "    captured_output = buffer.getvalue()\n",
    "\n",
    "    # Combine the response with the captured output and total processing time\n",
    "    agent_output = f\"Agents Steps:\\n{captured_output}\"\n",
    "    graded_response = f\"Graded Response:\\n{response}\"\n",
    "    processing_time = f\"Total Processing Time: {total_time:.2f} seconds\"\n",
    "\n",
    "    # Status messages for indicator panel\n",
    "\n",
    "    router_status_result = status_update(router_status)\n",
    "    router_choice_result = status_update(router_choice)\n",
    "    retrieve_status_result = status_update(retrieve_status)\n",
    "    rerank_status_result = status_update(rerank_status)\n",
    "    relevance_status_result = status_update(relevance_status)\n",
    "    web_fallback_status_result = status_update(web_fallback_status)\n",
    "    websearch_status_result = status_update(websearch_status)\n",
    "    hallucination_status_result = status_update(hallucination_status)\n",
    "    usefulness_status_result = status_update(usefulness_status)\n",
    "    vectorstore_files = get_unique_files(merged_documents)\n",
    "    \n",
    "    # if using rag-toggle\n",
    "    if basic_rag_toggle:\n",
    "        basic_rag_response, basic_rag_formatted_output_source_docs = get_rag_response(question)\n",
    "        # agent_output = \"Agent not used\"\n",
    "        relevance_status = \"Agent not used\"\n",
    "        web_fallback_status = \"Agent not used\"\n",
    "        websearch_status = \"Agent not used\"\n",
    "        hallucination_status = \"Agent not used\"\n",
    "        usefulness_status = \"Agent not used\"\n",
    "\n",
    "        relevance_status_result = status_update(relevance_status)\n",
    "        web_fallback_status_result = status_update(web_fallback_status)\n",
    "        websearch_status_result = status_update(websearch_status)\n",
    "        hallucination_status_result = status_update(hallucination_status)\n",
    "        usefulness_status_result = status_update(usefulness_status)        \n",
    "        rag_only_docs_content = \"\\n\\n\".join(basic_rag_formatted_output_source_docs)\n",
    "\n",
    "        return basic_rag_response, processing_time, model_id, router_status_result, router_choice_result, retrieve_status_result, rerank_status_result, relevance_status_result, web_fallback_status_result, websearch_status_result, hallucination_status_result, usefulness_status_result, rag_only_docs_content, vectorstore_files\n",
    "\n",
    "\n",
    "    ### bring in filtered docs formatted from outside function, join the contents to make it look better in textbox in GUI\n",
    "    \n",
    "    filtered_docs_content = \"\\n\\n\".join(filtered_docs_formatted)\n",
    "    \n",
    "    # not using rag toggle, then return all items in response\n",
    "    \n",
    "    return graded_response, processing_time, model_id, router_status_result, router_choice_result, retrieve_status_result, rerank_status_result, relevance_status_result, web_fallback_status_result, websearch_status_result, hallucination_status_result, usefulness_status_result, filtered_docs_content, vectorstore_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42229271-2511-4d2a-8b4d-92d941977f74",
   "metadata": {},
   "source": [
    "### Example question array for GUI Example questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83f267b1-aa65-4d4d-a964-8cd8343199db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Edit data below for specific demos ----\n",
    "EXAMPLE_TITLES = [\n",
    "                     \"### Vector Search\",\n",
    "                     \"### Web Fallback\",\n",
    "                     \"### Web Search\",\n",
    "                 ]\n",
    "EXAMPLES = [\n",
    "\n",
    "###Vector Search\n",
    "\n",
    "               [\n",
    "        \"Create an email based on a summary of patient 20 and their experience at the clinic.  Please include all the details.\",\n",
    "        \"What can you say about sunscreen effectiveness in preventing melanoma?\",\n",
    "        \"Please summarize the clinical trial info we have on our drug ipilimumab for melanoma.\",\n",
    "        \"What are the key domains of population-based approaches to mental health?\",\n",
    "\n",
    "               ],\n",
    "\n",
    "### Web Fallback\n",
    "\n",
    "               [\n",
    "        \"I am young person with COVID, what is my survival rate?\",\n",
    "\n",
    "               ],\n",
    "\n",
    "### Web Search\n",
    "\n",
    "\t\t       [ \n",
    "        \"What year did the Bears football team win the super bowl?\",\n",
    "        \"What is the chemical makeup of water?\"\n",
    "               ],\n",
    "\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728eeb9-9312-488f-a6e3-f68e517ad2af",
   "metadata": {},
   "source": [
    "# GUI setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff1d7794-c52c-4b56-a66e-f9febf993f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://172.16.6.3:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://172.16.6.3:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.27.0, however version 4.44.1 is available, please upgrade.\n",
      "--------\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/gradio/queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/gradio/route_utils.py\", line 261, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/gradio/blocks.py\", line 1788, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/gradio/blocks.py\", line 1340, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/gradio/utils.py\", line 759, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_2105440/3506398011.py\", line 42, in get_agentic_response\n",
      "    for output in app.stream(inputs):\n",
      "  File \"/home/demo/miniconda3/envs/rag/lib/python3.10/site-packages/langgraph/pregel/__init__.py\", line 1301, in stream\n",
      "    raise GraphRecursionError(\n",
      "langgraph.errors.GraphRecursionError: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "\n",
      "List of unique files in merged loader, sorted by file type:\n",
      "\n",
      "http://172.16.6.3/docs/csv-powerscale-mount/healthcare.csv\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/mental_health_first_aid.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_screening.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/investigating-the-efficacy-of-osimertinib-and-crizotinib-in-phase-3-clinical-trials-on-anti-cancer.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_variants.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/understanding-pharmacology-covid-mrna.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_cells.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/ipilimumab-for-advanced-melanoma-a-pharmacologic-perspective.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/population_based_approach_to_mental_health.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/skin_cancer_prevention_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_update.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_predictor_in_older_patients.pdf\n",
      "http://172.16.6.3/docs/pdf-powerscale-mount/covid_depression_in_72_yr_old_case_study.pdf\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def clear_fields():\n",
    "    return \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\"\", \"\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"Health Clinic Assistant\") as demo:\n",
    "\n",
    "    gr.HTML('''\n",
    "    <style>\n",
    "        .custom-html {\n",
    "            border: 3px solid grey;\n",
    "            border-radius: 10px; /* Adjust the value to change the roundness */\n",
    "            padding: 10px; /* Optional: Adds some padding inside the border */\n",
    "            height: 200px; /* Set a fixed height */\n",
    "            overflow-y: auto; /* Optional: Adds a scrollbar if content overflows */            \n",
    "        }\n",
    "\n",
    "        .logo-container {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "        }\n",
    "        .logo-container img {\n",
    "            margin-right: 15px; /* Space between the image and the text */\n",
    "        }     \n",
    "        \n",
    "        body, .gradio-container {\n",
    "            background-color: black;\n",
    "            color: white; /* Optional: Change text color to white for better contrast */\n",
    "        }\n",
    "\n",
    "        .custom-link {\n",
    "            color: #DDA0DD; /* Light purple color */\n",
    "            text-decoration: none;\n",
    "        }\n",
    "\n",
    "        .textbox_id textarea {\n",
    "             color: red\n",
    "        }\n",
    "    </style>\n",
    "    ''')\n",
    "\n",
    "    \n",
    "## TITLE\n",
    "    with gr.Row():\n",
    "        gr.HTML(f\"\"\"<div class=\"logo-container\"><img src=\"/file=images/medical-symbol2.jpg\" width=\"100\" height=\"100\" \n",
    "        style=\"float: left; \n",
    "        vertical-align: middle; \n",
    "        margin-right: 15px;\">\n",
    "        <h2>Agentic RAG Health Clinic Assistant</h2>\n",
    "        </div>\n",
    "        \"\"\")            \n",
    "\n",
    "\n",
    "### Question input and RAG toggle panel\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            question = gr.Textbox(value=\"Enter your question\", label=\"Question\", lines=2, max_lines=2)\n",
    "            with gr.Row():\n",
    "                submit_button = gr.Button(\"Submit\")\n",
    "                clear_button = gr.Button(\"Clear\")  # Add the Clear button next to Submit button     \n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            # llm_choice = gr.Dropdown(choices=list(llm_options.keys()), label=\"Select LLM\", value=\"Nvidia-NIM-Llama-3.1-8b-instruct\") # set default choice\n",
    "            basic_rag_toggle = gr.Checkbox(label=\"Use Basic RAG\")\n",
    "            model_id = gr.Textbox(label=\"Model ID\")\n",
    "            processing_time = gr.Textbox(label=\"Processing Time\")\n",
    "\n",
    "    \n",
    "# Add space and a section divider\n",
    "    gr.Markdown(\"<hr>\")\n",
    "    \n",
    "### Response section\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            response = gr.Textbox(label=\"Response\", lines=10, max_lines=10)\n",
    "        # with gr.Column():\n",
    "        #     agent_output = gr.Textbox(label=\"Agent Steps\", lines=10, max_lines=10)\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"#### Router Status\")  # Add this line for the title\n",
    "            router_status_result = gr.HTML(label=\"Router Status\")\n",
    "            gr.Markdown(\"#### Router Choice\")  # Add this line for the title\n",
    "            router_choice_result = gr.HTML(label=\"Router Choice\")\n",
    "            gr.Markdown(\"#### Retrieve Status\")  # Add this line for the title\n",
    "            retrieve_status_result = gr.HTML(label=\"Retrieve Status\")\n",
    "            gr.Markdown(\"#### Rerank Status\")  # Add this line for the title\n",
    "            rerank_status_result = gr.HTML(label=\"Rerank Status\")\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"#### Relevance Check\")  # Add this line for the title\n",
    "            relevance_status_result = gr.HTML(label=\"Relevance Check\")\n",
    "            gr.Markdown(\"#### Web Fallback Check\")  # Add this line for the title\n",
    "            web_fallback_status_result = gr.HTML(label=\"Web Fallback Check\")\n",
    "            gr.Markdown(\"#### Web Search\")  # Add this line for the title\n",
    "            websearch_status_result = gr.HTML(label=\"Web Search\")\n",
    "            gr.Markdown(\"#### Hallucination Check\")  # Add this line for the title\n",
    "            hallucination_status_result = gr.HTML(label=\"Hallucination Check\")\n",
    "            gr.Markdown(\"#### Usefulness Check\")  # Add this line for the title\n",
    "            usefulness_status_result = gr.HTML(label=\"Usefulness Check\")    \n",
    "    \n",
    "# Add space and a section divider\n",
    "    gr.Markdown(\"<hr>\")\n",
    "\n",
    "### source documents HTML panel\n",
    "\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            gr.Markdown(\"#### Source Documents\")  # Add this line for the title\n",
    "            source_documents = gr.HTML(label=\"Source Documents\", elem_classes=\"custom-html\")\n",
    "        with gr.Column(scale=2):\n",
    "            vectorstore_files = gr.Textbox(label=\"Uploaded Files\", lines=10, max_lines=10)\n",
    "            \n",
    "    # with gr.Row():\n",
    "    #     with gr.Column():\n",
    "    #         vectorstore_files = gr.Textbox(label=\"Vectorstore Files\", lines=10, max_lines=10)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Add space and a section divider\n",
    "    gr.Markdown(\"<hr>\")\n",
    "\n",
    "########## EXAMPLE QUICK PROMPT BUTTONS ###########\t    \n",
    "    def example_click(user_input):\n",
    "        return user_input\n",
    "\n",
    "    title_counter = 0\n",
    "    for list_entry in EXAMPLES:\n",
    "        if len(EXAMPLE_TITLES[title_counter]) > 0:\n",
    "            gr.Markdown(EXAMPLE_TITLES[title_counter])\n",
    "        with gr.Row():\n",
    "            for entry in list_entry:\n",
    "                button = gr.Button(entry)\n",
    "                button.click(fn=example_click, inputs=button, outputs=question)\n",
    "            title_counter += 1\n",
    "####################################\t\n",
    "\n",
    "\n",
    "###  Gradio inputs go from the GUI --> to the function. \n",
    "###  Outputs are coming OUT of the function into the GUI in that order.  Naming doesn't matter.\n",
    "###  the return statement of the function needs to return in the order that matches the outputs in gradio\n",
    "\n",
    "    submit_button.click(\n",
    "        get_agentic_response, \n",
    "        inputs=[question, basic_rag_toggle], \n",
    "        outputs=[response, processing_time, model_id, router_status_result, router_choice_result, retrieve_status_result, rerank_status_result, relevance_status_result, web_fallback_status_result, websearch_status_result, hallucination_status_result, usefulness_status_result, source_documents, vectorstore_files]\n",
    "    )\n",
    "\n",
    "    clear_button.click(\n",
    "        clear_fields, \n",
    "        inputs=[], \n",
    "        outputs=[question, response, processing_time, model_id, router_status_result, router_choice_result, retrieve_status_result, rerank_status_result, relevance_status_result, web_fallback_status_result, websearch_status_result, hallucination_status_result, usefulness_status_result, source_documents, vectorstore_files]\n",
    "    )    \n",
    "\n",
    "\n",
    "\n",
    "demo.queue(max_size=5)\n",
    "demo.launch(share=False, debug=True, server_name=\"172.16.6.3\", server_port=7869, allowed_paths=[\"images/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6047541-7bae-4350-aeed-7a68fb69b6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
