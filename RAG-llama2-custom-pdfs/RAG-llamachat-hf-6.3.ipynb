{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dc7e39-dd9a-43e3-8d9a-f77af583004c",
   "metadata": {},
   "source": [
    "### RAG Llama2-Chat-7b-Huggingface Chatbot\n",
    "- Gradio front end\n",
    "- Chromadb vector database\n",
    "- PDF file dataset from https://infohub.delltechnologies.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d4d542-e238-4948-ade3-efb972c78cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub==0.16.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub==0.16.4) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub==0.16.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub==0.16.4) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub==0.16.4) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub==0.16.4) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /home/demouser/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "## code to auto login to hugging face, avoid the login prompt\n",
    "\n",
    "## your hugging face hub version has a lot of libraries that are used throughout.  Try to solve any dependencies with this if you experience errors. \n",
    "#import sys\n",
    "#!{sys.executable} -m pip install --force-reinstall huggingface-hub==0.16.4 \n",
    "\n",
    "%pip install huggingface-hub==0.16.4\n",
    "\n",
    "# get your account token from https://huggingface.co/settings/tokens\n",
    "token = 'XXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e35f8a-540d-44b3-91f0-a5f1f17f03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install python libraries and applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac77491-212f-450d-ae73-2448c3422379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (0.0.331)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (0.0.58)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chromadb in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (0.4.15)\n",
      "Requirement already satisfied: requests>=2.28 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (2.4.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (0.104.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (4.8.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (1.16.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (1.20.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (0.14.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (6.1.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (1.59.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (28.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (6.0.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.23.4)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.6.4)\n",
      "Requirement already satisfied: requests-oauthlib in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: coloredlogs in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
      "Requirement already satisfied: protobuf in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.0)\n",
      "Requirement already satisfied: sympy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.8.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.61.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.20.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.20.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.41b0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.41b0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.16.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.15.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pypdf in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (3.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: xformers in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (0.0.22.post7)\n",
      "Requirement already satisfied: numpy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from xformers) (1.26.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from xformers) (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch==2.1.0->xformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence_transformers in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (4.35.0)\n",
      "Requirement already satisfied: tqdm in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (0.16.0)\n",
      "Requirement already satisfied: numpy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers) (12.3.52)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: InstructorEmbedding in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pdf2image in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (1.16.3)\n",
      "Requirement already satisfied: pillow in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pdf2image) (10.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pycryptodome in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (3.19.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cython in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (3.0.5)\n",
      "Requirement already satisfied: cchardet in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (2.1.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gradio in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (4.1.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (5.1.2)\n",
      "Requirement already satisfied: fastapi in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.104.1)\n",
      "Requirement already satisfied: ffmpy in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.7.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.7.0)\n",
      "Requirement already satisfied: httpx in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (6.1.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: numpy~=1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (1.26.0)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: packaging in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (2.1.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (10.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (2.4.2)\n",
      "Requirement already satisfied: pydub in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (0.24.0.post1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio) (11.0.3)\n",
      "Requirement already satisfied: fsspec in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from gradio-client==0.7.0->gradio) (2023.10.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Requirement already satisfied: toolz in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests~=2.0->gradio) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from httpx->gradio) (1.0.1)\n",
      "Requirement already satisfied: sniffio in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/demouser/miniconda3/envs/rag/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U pip\n",
    "%pip install torch\n",
    "%pip install transformers\n",
    "%pip install langchain\n",
    "%pip install chromadb\n",
    "%pip install pypdf\n",
    "%pip install xformers\n",
    "%pip install sentence_transformers\n",
    "%pip install InstructorEmbedding\n",
    "%pip install pdf2image\n",
    "%pip install pycryptodome\n",
    "%pip install cython cchardet\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1132dd-4463-45fe-997f-2136c13464af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check installed GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0a0592-b751-4f5c-b97c-5cd12e8baef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  2 18:22:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 PCIe               Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              50W / 350W |      4MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    Off | 00000000:B5:00.0 Off |                    0 |\n",
      "| N/A   41C    P8              35W / 350W |      3MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb3e4a-af6a-4852-98a0-97afaff2924c",
   "metadata": {},
   "source": [
    "### Assign GPU environment vars and ID order\n",
    "\n",
    "NOTE:  to change which GPU you want visible, simply change the CUDA VISIBLE DEVICES ID to the GPU you prefer. \n",
    "This method guarantees no confusion or misplaced workloads on any GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88bf410b-3b71-4299-8bc9-0b6fb09f4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THESE VARIABLES MUST APPEAR BEFORE TORCH OR CUDA IS IMPORTED\n",
    "## set visible GPU devices and order of IDs to the PCI bus order\n",
    "## target the L40s that is on ID 1\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"   \n",
    "\n",
    "## this integer corresponds to the ID of the GPU, for multiple GPU use \"0,1,2,3\"...\n",
    "## to disable all GPUs, simply put empty quotes \"\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846fa67-69d7-478e-995e-d16a5ba98f72",
   "metadata": {},
   "source": [
    "### Investigate our GPU and CUDA environment\n",
    "\n",
    "NOTE:  If you are only using 1 single GPU in the visibility settings above, then the active CUDA device will always be 0 since it is the only GPU seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaec1edd-9c18-4b1f-a0e8-e3ed03b3141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Python, Pytorch, Cuda info____\n",
      "__Python VERSION: 3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]\n",
      "__pyTorch VERSION: 2.1.0+cu121\n",
      "__CUDA RUNTIME API VERSION\n",
      "__CUDNN VERSION: 8902\n",
      "_____nvidia-smi GPU details____\n",
      "index, name, driver_version, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA H100 PCIe, 535.129.03, 81559 MiB, 4 MiB, 81003 MiB\n",
      "1, NVIDIA L40S, 535.129.03, 46068 MiB, 3 MiB, 45593 MiB\n",
      "_____Device assignments____\n",
      "Number CUDA Devices: 1\n",
      "Current cuda device:  0  **May not correspond to nvidia-smi ID above, check visibility parameter\n",
      "Device name:  NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from subprocess import call\n",
    "print('_____Python, Pytorch, Cuda info____')\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA RUNTIME API VERSION')\n",
    "#os.system('nvcc --version')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('_____nvidia-smi GPU details____')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('_____Device assignments____')\n",
    "print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "print ('Current cuda device: ', torch.cuda.current_device(), ' **May not correspond to nvidia-smi ID above, check visibility parameter')\n",
    "print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b639b742-c004-4bcd-9dd6-298a0fc499d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain import HuggingFacePipeline, PromptTemplate\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "#from langchain.chains import ConversationalRetrievalChain\n",
    "#from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "#from langchain.chains import RetrievalQA\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from pdf2image import convert_from_path\n",
    "from transformers import AutoTokenizer, pipeline, TextIteratorStreamer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bae0d5-b6ef-425b-9e29-13393a839bcf",
   "metadata": {},
   "source": [
    "### Assign single GPU to device variable\n",
    "\n",
    "This command assigns GPU ID 0 to the DEVICE variable called \"cuda:0\" if pytorch can actually reach and speak with the GPU using cuda language.  Else it will use the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26efcc3-328c-49fe-9fe6-bbdbec423b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7481a10-af9f-4154-bddb-e429d4361ecf",
   "metadata": {},
   "source": [
    "### Clear GPU memory from any previous runs\n",
    "- assume Nvidia drivers installed\n",
    "- When running notebooks over and over again, often much of the memory is still in the GPU memory allocated cache.  Depending on the size of the GPU, this might cause out of memory issues during the next run.  It is advised to clear out the cache, or restart the kernel.\n",
    "- here we see multiple GPUs, the memory usage, any running processes and our CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14cfe3b9-5c65-4708-ad97-5bb3a04d2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6559d3-b08a-4ecb-a00c-cddba9f958e2",
   "metadata": {},
   "source": [
    "### Clear the previous run vector database\n",
    "\n",
    "This is optional, the vector db will be rebuilt.  For a completely fresh run you can delete the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4084ec3-db2b-475d-8e4b-5ea3f980879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove chroma vector db local db folder from previous run\n",
    "\n",
    "!rm -rf \"db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee7825-5a61-4950-aa5a-c1a905592d1b",
   "metadata": {},
   "source": [
    "### Prepare data from knowledge base\n",
    "\n",
    "- load the pdf files\n",
    "- use an instruct model to intelligently split the content into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62e497d-7740-4162-bb56-80c6845e06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"pdfs-dell-infohub\")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf945d8-2c0d-48d3-b08f-31f71fd61d34",
   "metadata": {},
   "source": [
    "### Use Instruct model to split text intelligently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad384a01-6147-4251-abfe-2329b7bb3f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a0824-cb0b-476a-83aa-b667481be306",
   "metadata": {},
   "source": [
    "### Chunk text\n",
    "\n",
    "<b>chunk size large</b>:  If you want to provide large text overviews and summaries in your responses - appropriate for content creation tasks - then a large chunk size is helpful.  800 or higher.\n",
    "\n",
    "<b>chunk size small</b>:  If you are looking for specific answers based on extracted content from your knowledge base, a smaller chunk size is better.  Smaller than 800.\n",
    "\n",
    "<b>chunk overlap</b>:  If the paragraphs of content in your PDFs often refer to previous content in the document, like a large whitepaper, you might want to have a good size overlap.  128 or higher, this is totally up to the content.\n",
    "\n",
    "https://dev.to/peterabel/what-chunk-size-and-chunk-overlap-should-you-use-4338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96d8efbb-ad52-4405-ab9f-a1d0d2c6cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=32)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63daf97c-4329-4eb9-a71d-d8d167cdac8e",
   "metadata": {},
   "source": [
    "### Create the vector database\n",
    "- take converted embeddings and place them into vector db\n",
    "- stored locally on prem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f66d7b58-24c6-4ba5-beea-74c8c7fe7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectordb = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")\n",
    "\n",
    "### vectordb = Chroma.from_texts(texts, embeddings, persist_directory=\"db\", metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(texts))])\n",
    "\n",
    "print('\\n' + 'Time to complete:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b18985-3e4d-4782-8e5d-ed7bff178e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load vector db if you've already created it --- comment this out and uncomment the above loader, splitter cells to create new vector db\n",
    "\n",
    "vectordb = Chroma(persist_directory=\"./db\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb479809-eb88-4862-8cb3-d352c2752de7",
   "metadata": {},
   "source": [
    "### Prepare Chat model\n",
    "\n",
    "Llama2 7b chat chosen for this use case for its optimized human dialogue.  https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95f9a50-c55b-4677-9577-ac186e31ac8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3967b88965d47aaba3ca039e45ad7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.use_default_system_prompt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967d50a-d145-4ad8-8c82-05a5039d9835",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa0ee97-3c43-4949-a721-8aed3b736dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MAX_NEW_TOKENS = 2048\n",
    "DEFAULT_MAX_NEW_TOKENS = 1024\n",
    "MAX_INPUT_TOKEN_LENGTH = int(os.getenv(\"MAX_INPUT_TOKEN_LENGTH\", \"4096\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b5a3b-4df9-44dc-85ee-6fc951141750",
   "metadata": {},
   "source": [
    "### Process chat input function\n",
    "\n",
    "to use Gradio you need to have a function that handles the chat processing. The function defines the expected positional arguments that the Gradio interface will output to your function.  Using that data as input into your function, the positional variables are all mapped to their correct variables.  From what I can figure out, the 1st returned position is the user's query (user_message), 2nd is the chat history (chat_history), 3rd is the system prompt and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f02c7468-c1e5-4553-8573-4eca197c4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "set_debug(True)\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420082c5-f432-4007-8feb-e3d60cdcb685",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### MEMORY PARAMETERS ###########\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5, ## number of interactions to keep in memory\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,  ## formats the chat_history into HumanMessage and AImessage entity list\n",
    "    input_key=\"question\",\n",
    "    output_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "347e5d7b-738c-41fc-af67-3770632a94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this chunk works, however it gives constant clarifying questions... annoying but the responses are pretty decent sometimes.\n",
    "def process_input(question,\n",
    "    chat_history,\n",
    "    system_prompt,\n",
    "    max_new_tokens,\n",
    "    temperature,\n",
    "    top_p,\n",
    "    top_k,\n",
    "    repetition_penalty\n",
    "                 ):\n",
    "\n",
    "    ### let's check and see that our gradio interface is passing the input variables as we expect\n",
    "    ### Change the values of sliders in gradio at run time to make changes to the inputs here\n",
    "    # print(\"SYS:\", system_prompt) \n",
    "    # print(\"ch:\", chat_history)\n",
    "    # print(\"MAX_NEW_TOKENS:\", max_new_tokens, \"T:\", temperature, \"P:\", top_p, \"K:\", top_k, \"REP_PEN:\", repetition_penalty)\n",
    "\n",
    "    \n",
    "    ### system prompt variable is typed in by the user in Gradio advanced settings text box and sent into process_input function\n",
    "    ### This is Llama2 prompt format \n",
    "    ### https://huggingface.co/blog/llama2#how-to-prompt-llama-2\n",
    "\n",
    "#    llama2_prompt_template = \"\\n\\n [INST] <<SYS>>\" + system_prompt + \"<</SYS>>\\n\\n Context: {context} \\n\\n  Chat History: {chat_history} \\n\\n  Question: {question} \\n\\n[/INST]\".strip()\n",
    "    llama2_prompt_template = \"\\n\\n [INST] <<SYS>>\" + system_prompt + \"<</SYS>>\\n\\n Summaries: {summaries} \\n\\n  Chat History: {chat_history} \\n\\n  Question: {question}\\n\\n[/INST]\".strip()\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "#        input_variables=[\"context\", \"chat_history\", \"question\"], \n",
    "        input_variables=[\"summaries\", \"chat_history\", \"question\"], \n",
    "        template=llama2_prompt_template\n",
    "    )\n",
    "\n",
    "    ####  check to see what the prompt actually looks like\n",
    "    \n",
    "#    print(PROMPT)\n",
    "\n",
    "    ####### STREAMER FOR TEXT OUTPUT ############\n",
    "    \n",
    "    streamer = TextIteratorStreamer(tokenizer, timeout=10.0, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "    ####### PIPELINE ARGUMENTS FOR THE LLM ############\n",
    "    ### more info at https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539\n",
    "    \n",
    "    text_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    do_sample=True,\n",
    "#    num_beams=2, beam search over 1 cannot be used with streamer\n",
    "    streamer=streamer,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    top_p=top_p,\n",
    "    top_k=top_k,\n",
    "    temperature=temperature,\n",
    "    repetition_penalty=repetition_penalty,\n",
    "    )\n",
    "\n",
    "    ####### ATTACH PIPELINE TO LLM ############\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=text_pipeline)\n",
    "\n",
    "    \n",
    "#########\n",
    "######### TESTING DIFFERENT CHAINS\n",
    "#########\n",
    "    \n",
    "    # ###### CONVERSATION CHAIN PARAMS ###########\n",
    "    ### BEWARE - this WILL rephrase the question and context into a standalone NEW question, might not work well for tech docs\n",
    "\n",
    "    \n",
    "    # conv_chain = ConversationalRetrievalChain.from_llm(\n",
    "    #     llm=llm,\n",
    "    #     combine_docs_chain_kwargs={\"prompt\": PROMPT},    ### combine docs chain brings in a custom prompt template     \n",
    "    #     retriever=vectordb.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    #     chain_type=\"stuff\",\n",
    "    #     return_source_documents = True,\n",
    "    #     memory=memory,\n",
    "    #     get_chat_history=lambda h : h,\n",
    "    #     verbose=True,\n",
    "    #     rephrase_question=False,\n",
    "    #     )\n",
    "\n",
    "\n",
    "    # ###### RETRIEVAL QA FROM LLM PARAMS ###########\n",
    "    # qa_chain = RetrievalQA.from_llm(\n",
    "    #     llm=llm,\n",
    "    #     prompt=PROMPT,\n",
    "    #     retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    #     return_source_documents = True,\n",
    "    #     memory=memory,\n",
    "    #     verbose=True,\n",
    "    #     )\n",
    "\n",
    "\n",
    "    \n",
    "########  RETRIEVAL QA WITH SOURCES WORKS FAIRLY WELL IN OUR USE CASE\n",
    "    \n",
    "    ### this does NOT rephrase the question\n",
    "\n",
    "    ### info on db retriever settings:  https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore\n",
    "    ### Maximum marginal relevance retrieval (mmr) will provide a more broad selection from more files\n",
    "    ## search kwargs integer is the max number of docs to return in the response\n",
    "    \n",
    "    ###### RETRIEVAL QA FROM CHAIN TYPE PARAMS ###########\n",
    "    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": PROMPT},\n",
    "        retriever=vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4}),\n",
    "#        retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 4}),\n",
    "        return_source_documents = True,\n",
    "        memory=memory,\n",
    "        verbose=True,\n",
    "        )\n",
    "\n",
    "\n",
    "#    response = conv_chain({\"question\": question, \"chat_history\": chat_history})\n",
    "\n",
    "    ### this response format is best for retrieval QA chain with sources ###\n",
    "    ### Gradio will respond with only 2 arguments from chatbot.interface, first will always be the question, second will be history\n",
    "    \n",
    "    response = qa_chain(question, chat_history)\n",
    "\n",
    "    ##### TEST THE RESPONSE ######\n",
    "    \n",
    "#    print(response)\n",
    "#    print(response[\"chat_history\"])\n",
    "#    print(response[\"answer\"])\n",
    "\n",
    "\n",
    "    ##### TEST SOURCE DOCS lIST ######\n",
    "    \n",
    "    print(\"============================================\")\n",
    "    print(\"===============Source Documents============\")\n",
    "    print(\"============================================\")\n",
    "\n",
    "    for x in range(len(response[\"source_documents\"][0].metadata)):\n",
    "        print(response[\"source_documents\"][x].metadata)\n",
    "\n",
    "    print(\"============================================\")\n",
    "    print(\"============================================\")\n",
    "\n",
    "    #### chat history will be empty key if there is no actual history yet, run the bot a few times\n",
    "    \n",
    "#    print(response.keys())\n",
    "    # print(response[\"answer\"])\n",
    "#    print(response[\"sources\"])\n",
    "    \n",
    "    \n",
    "    ####### MANAGE OUTPUT ARRAY FROM STREAMER ###########\n",
    "    ## whatever is in streamer, the positional argument 'text', take it and join it all together\n",
    "    ## yield allows streaming in Gradio\n",
    "    \n",
    "    outputs = []\n",
    "    for text in streamer:\n",
    "        outputs.append(text)\n",
    "        yield \"\".join(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9388d-8f46-44d9-a153-c2b34bc8434b",
   "metadata": {},
   "source": [
    "### Build the Gradio GUI\n",
    "- Gradio is a quick, highly customizable UI package for your python applications:  https://www.gradio.app/\n",
    "- Combined with langchain, gradio can trigger multiple chains for a wide variety of user interactions.\n",
    "\n",
    "<b>NOTE</b>:  Gradio will output variables in the order they appear here in the interface object. There is no declaration of these variables explicitly in the creation of each one when it is sent to the processing function.  i.e. slider for temperature is the 3rd variable in the list.  It is passed as a positional argument, not as \"temperature\" variable explicitly.  You have to take those positional arguments that gradio passes out (from the user input at the browser) as positional input into your chat processing function.  \n",
    "\n",
    "#### Access the UI\n",
    "- The provided code forces Gradio to create a small web server on the local host the notebook is being served from\n",
    "- Gradio will provide a URL that can be used in a web browser, that must be accessed from within the same network, so you may need to access it using a jumphost.  In this case we used a Windows jump host and Chrome browser on the same network to access the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537952ee-d0b4-4bc1-a721-9cc7013f086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://172.16.6.3:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://172.16.6.3:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Provide a summary on VXrail cluster aware updating\",\n",
      "  \"chat_history\": []\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Provide a summary on VXrail cluster aware updating\",\n",
      "  \"chat_history\": [],\n",
      "  \"summaries\": \"Content: Figure 11.  VxRail Hyperconverged Infrastructure  \\n \\nVxRail provide s automated end- to-end lif e cycle management  and helps  moderniz e data \\ncenter s across edge, core, and cloud, offering the following features and benefits : \\n• Turnkey appliance, jointly developed by Dell Technologies  and VMware  \\n• Fully integrated, preconfigured, and tested  \\n• Intel-based on Dell PowerEdge servers with vSphere and vSAN  \\n• Streamlined deployment and maintenance using VxRail Manager\\nSource: pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf\\n\\nContent: full-stack , single -click life  cycle management through VxRail Manager . \\nNode types  are standardized  combinations of compute, memory, storage, and networking \\nresources —defined by a fixed physical memory to a physical core ratio and powered by \\nVxRail. They are optimized for your virtualized and containerized workload requirements, \\nranging from small (4  GB) to extra -large (32  GB) memory -to-CPU core ratios. We also\\nSource: pdfs-dell-infohub/h19751-aiml-platform-on-a-gpu-enabled-dell-apex-private-cloud-with-rancher-prime.pdf\\n\\nContent:  In scenarios where data center space or ownership is an issue, the VxRail D -\\nSeries can be deployed outside of the data center , if the area or room in which \\nit is deployed meets environmental requirements.  \\n \\nThe edge helps  manufactur ers realize new business outcomes  as they move toward \\ntoday’s future -focused Industry 4.0 and smart manufacturing ideals . The key technologies \\npowering these new paradigms  include:  \\n• Artificial Intelligence (AI)  \\n• Internet of Things (I oT)\\nSource: pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf\\n\\nContent: Hyperconverged Infrastructure (HCI) between Dell and VMware. Built on PowerEdge \\nserver platforms , it integrates  Dell Technologies  and VMware data services  including \\ncompression, deduplication, replication, and backup.  \\nVxRail delivers resiliency and centralized -management functionality  for fast, easy  \\nmanagement of consolidated workloads, virtual desktops, business applications, and edge infrastructure.  \\nThe following is an overview of the VxRail HCI:\\nSource: pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"[INST] <<SYS>>You are a technical research assistant, you answer only in English language. Your audience appreciates technical details in your answer.  Using the provided summaries of context and the chat history provided, please respond in a helpful, concise manner.<</SYS>>\\n\\n Summaries: Content: Figure 11.  VxRail Hyperconverged Infrastructure  \\n \\nVxRail provide s automated end- to-end lif e cycle management  and helps  moderniz e data \\ncenter s across edge, core, and cloud, offering the following features and benefits : \\n• Turnkey appliance, jointly developed by Dell Technologies  and VMware  \\n• Fully integrated, preconfigured, and tested  \\n• Intel-based on Dell PowerEdge servers with vSphere and vSAN  \\n• Streamlined deployment and maintenance using VxRail Manager\\nSource: pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf\\n\\nContent: full-stack , single -click life  cycle management through VxRail Manager . \\nNode types  are standardized  combinations of compute, memory, storage, and networking \\nresources —defined by a fixed physical memory to a physical core ratio and powered by \\nVxRail. They are optimized for your virtualized and containerized workload requirements, \\nranging from small (4  GB) to extra -large (32  GB) memory -to-CPU core ratios. We also\\nSource: pdfs-dell-infohub/h19751-aiml-platform-on-a-gpu-enabled-dell-apex-private-cloud-with-rancher-prime.pdf\\n\\nContent:  In scenarios where data center space or ownership is an issue, the VxRail D -\\nSeries can be deployed outside of the data center , if the area or room in which \\nit is deployed meets environmental requirements.  \\n \\nThe edge helps  manufactur ers realize new business outcomes  as they move toward \\ntoday’s future -focused Industry 4.0 and smart manufacturing ideals . The key technologies \\npowering these new paradigms  include:  \\n• Artificial Intelligence (AI)  \\n• Internet of Things (I oT)\\nSource: pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf\\n\\nContent: Hyperconverged Infrastructure (HCI) between Dell and VMware. Built on PowerEdge \\nserver platforms , it integrates  Dell Technologies  and VMware data services  including \\ncompression, deduplication, replication, and backup.  \\nVxRail delivers resiliency and centralized -management functionality  for fast, easy  \\nmanagement of consolidated workloads, virtual desktops, business applications, and edge infrastructure.  \\nThe following is an overview of the VxRail HCI:\\nSource: pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf \\n\\n  Chat History: [] \\n\\n  Question: Provide a summary on VXrail cluster aware updating\\n\\n[/INST]\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] [6.02s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"  Sure! Based on the provided content and chat history, here's a summary of VxRail cluster aware updating:\\n\\nVxRail provides automated end-to-end lifecycle management for modernizing data centers across edge, core, and cloud environments. As part of its feature set, VxRail offers cluster aware updating, which enables customers to update their entire cluster simultaneously without downtime or manual intervention. This feature streamlines the updating process, reducing complexity and improving overall efficiency.\\n\\nCluster aware updating in VxRail works by leveraging advanced algorithms that monitor the health of each node in the cluster and determine the optimal time for updates. Once the algorithm identifies the best window for updating, VxRail automatically applies the necessary changes to all nodes in the cluster, ensuring consistent configuration across the environment.\\n\\nBy utilizing this feature, organizations can reduce the risk of human error during updates, minimize downtime, and improve overall system stability. Cluster aware updating also enables organizations to quickly adapt to changing business needs and take advantage of new features and capabilities as they become available.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [6.02s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"  Sure! Based on the provided content and chat history, here's a summary of VxRail cluster aware updating:\\n\\nVxRail provides automated end-to-end lifecycle management for modernizing data centers across edge, core, and cloud environments. As part of its feature set, VxRail offers cluster aware updating, which enables customers to update their entire cluster simultaneously without downtime or manual intervention. This feature streamlines the updating process, reducing complexity and improving overall efficiency.\\n\\nCluster aware updating in VxRail works by leveraging advanced algorithms that monitor the health of each node in the cluster and determine the optimal time for updates. Once the algorithm identifies the best window for updating, VxRail automatically applies the necessary changes to all nodes in the cluster, ensuring consistent configuration across the environment.\\n\\nBy utilizing this feature, organizations can reduce the risk of human error during updates, minimize downtime, and improve overall system stability. Cluster aware updating also enables organizations to quickly adapt to changing business needs and take advantage of new features and capabilities as they become available.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain] [6.02s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"  Sure! Based on the provided content and chat history, here's a summary of VxRail cluster aware updating:\\n\\nVxRail provides automated end-to-end lifecycle management for modernizing data centers across edge, core, and cloud environments. As part of its feature set, VxRail offers cluster aware updating, which enables customers to update their entire cluster simultaneously without downtime or manual intervention. This feature streamlines the updating process, reducing complexity and improving overall efficiency.\\n\\nCluster aware updating in VxRail works by leveraging advanced algorithms that monitor the health of each node in the cluster and determine the optimal time for updates. Once the algorithm identifies the best window for updating, VxRail automatically applies the necessary changes to all nodes in the cluster, ensuring consistent configuration across the environment.\\n\\nBy utilizing this feature, organizations can reduce the risk of human error during updates, minimize downtime, and improve overall system stability. Cluster aware updating also enables organizations to quickly adapt to changing business needs and take advantage of new features and capabilities as they become available.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain] [6.71s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "============================================\n",
      "===============Source Documents============\n",
      "============================================\n",
      "{'page': 28, 'source': 'pdfs-dell-infohub/h19739-dell-apex-edge-with-litmus-wp.pdf'}\n",
      "{'page': 5, 'source': 'pdfs-dell-infohub/h19751-aiml-platform-on-a-gpu-enabled-dell-apex-private-cloud-with-rancher-prime.pdf'}\n",
      "============================================\n",
      "============================================\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"[INST] <<SYS>>You are a technical research assistant, you answer only in English language. Your audience appreciates technical details in your answer.  Using the provided summaries of context and the chat history provided, please respond in a helpful, concise manner.<</SYS>>\\n\\n Summaries: Content: now be choreographed across a cluster by providing a list of nodes to be simultaneously updated. The upgrade helper tool can be used to select a combination of nodes that can \\nbe updated simultaneously and an explicit list of nodes that should not be updated \\ntogether (for example, nodes in a node- pair).  \\n \\nA rolling upgrade individually  upgrades and restarts each node in the cluster sequentially. \\nDuring a rolling upgrade, the cluster remains online and continues serving data to clients\\nSource: pdfs-dell-infohub/h10588-isilon-data-availability-protection-wp.pdf\\n\\nContent: 24. Ensure that all information is correct before proceeding.  \\nNote : If changes are required, then each step  in this section  must be repeated . You cannot \\nupdate a single item.  \\n25. Once all information is confirmed, click FINISH . \\n26. While the cluster is under configuration, you can review the m by selecting the \\nhyperlink (for example, 1) in the Config Status column. The output is shown in \\nFigure 68.\\nSource: pdfs-dell-infohub/h19672_deploying_dell_powerflex_with_vmware_tanzu .pdf\\n\\nContent: the cluster. Partial upgrade is also permitted, whereby a subset of cluster nodes can be \\nupgraded. The subset of nodes may also be grown during the upgrade. Beginning with Automatic drive \\nfirmware \\nupdates  \\nRolling upgrade  \\nNondisruptive \\nupgrades\\nSource: pdfs-dell-infohub/h10588-isilon-data-availability-protection-wp.pdf\\n\\nContent: where 1,500 GiB/hr is the lower bound (as seen in internal testing ). \\n \\nA cluster supports automatic drive firmware updates for new and replacement drives, as \\npart of the nondisruptive firmware update process. Firmware updates are delivered using \\ndrive support packages, which both simplify and streamline the management of exis ting \\nand new drives across the cluster. This ensures that drive firmware is up to date and\\nSource: pdfs-dell-infohub/h10588-isilon-data-availability-protection-wp.pdf \\n\\n  Chat History: [HumanMessage(content='Provide a summary on VXrail cluster aware updating'), AIMessage(content=\\\"  Sure! Based on the provided content and chat history, here's a summary of VxRail cluster aware updating:\\\\n\\\\nVxRail provides automated end-to-end lifecycle management for modernizing data centers across edge, core, and cloud environments. As part of its feature set, VxRail offers cluster aware updating, which enables customers to update their entire cluster simultaneously without downtime or manual intervention. This feature streamlines the updating process, reducing complexity and improving overall efficiency.\\\\n\\\\nCluster aware updating in VxRail works by leveraging advanced algorithms that monitor the health of each node in the cluster and determine the optimal time for updates. Once the algorithm identifies the best window for updating, VxRail automatically applies the necessary changes to all nodes in the cluster, ensuring consistent configuration across the environment.\\\\n\\\\nBy utilizing this feature, organizations can reduce the risk of human error during updates, minimize downtime, and improve overall system stability. Cluster aware updating also enables organizations to quickly adapt to changing business needs and take advantage of new features and capabilities as they become available.\\\")] \\n\\n  Question: document the process of a cluster aware upate for VXrail\\n\\n[/INST]\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] [13.44s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"  Certainly! Here's a detailed explanation of the process involved in conducting a cluster-aware update for VxRail:\\n\\nStep 1: Preparation - Before starting the update process, it's essential to ensure that the cluster is properly configured and all necessary prerequisites are met. This includes verifying that the latest software versions are installed, validating the integrity of the storage subsystem, and confirming that the network infrastructure is stable and capable of handling the update process.\\n\\nStep 2: Identify Nodes to be Upgraded - Use the VxRail Manager interface to identify the nodes that need to be upgraded. This involves selecting the appropriate criteria for determining which nodes should be included in the update process. For instance, you might choose to upgrade nodes based on factors such as CPU age, memory usage, or disk usage.\\n\\nStep 3: Create an Update Plan - After identifying the nodes to be upgraded, create an update plan that outlines the steps involved in the upgrade process. This plan should include the sequence of actions to be taken, the estimated duration for each action, and any potential risks or issues that could arise during the update.\\n\\nStep 4: Apply the Update - With the update plan in place, apply the updates to the identified nodes one at a time. During this phase, the VxRail Manager will perform various checks to ensure that the update is applied correctly and without disrupting the operation of the cluster. These checks may include verifying the consistency of the file systems, checking the status of the kernel and device drivers, and ensuring that all critical services are functioning correctly.\\n\\nStep 5: Verify the Results - Once the update has been applied to all nodes in the cluster, verify that the update was successful. This may involve running diagnostic tests to validate the functionality of the cluster, checking the logs to ensure that there were no errors during the update process, and monitoring the performance of the cluster to ensure that it's operating within expected parameters.\\n\\nStep 6: Post-Update Validation - After completing the update, run additional validation checks to ensure that the cluster is operating correctly. This may involve verifying that all services are running, checking the status of the storage subsystem, and ensuring that network connectivity is established between nodes.\\n\\nBy following these steps, organizations can effectively implement cluster-aware updates for their VxRail clusters, ensuring minimal disruption to operations while maintaining a highly available and optimized IT infrastructure.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [13.44s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"  Certainly! Here's a detailed explanation of the process involved in conducting a cluster-aware update for VxRail:\\n\\nStep 1: Preparation - Before starting the update process, it's essential to ensure that the cluster is properly configured and all necessary prerequisites are met. This includes verifying that the latest software versions are installed, validating the integrity of the storage subsystem, and confirming that the network infrastructure is stable and capable of handling the update process.\\n\\nStep 2: Identify Nodes to be Upgraded - Use the VxRail Manager interface to identify the nodes that need to be upgraded. This involves selecting the appropriate criteria for determining which nodes should be included in the update process. For instance, you might choose to upgrade nodes based on factors such as CPU age, memory usage, or disk usage.\\n\\nStep 3: Create an Update Plan - After identifying the nodes to be upgraded, create an update plan that outlines the steps involved in the upgrade process. This plan should include the sequence of actions to be taken, the estimated duration for each action, and any potential risks or issues that could arise during the update.\\n\\nStep 4: Apply the Update - With the update plan in place, apply the updates to the identified nodes one at a time. During this phase, the VxRail Manager will perform various checks to ensure that the update is applied correctly and without disrupting the operation of the cluster. These checks may include verifying the consistency of the file systems, checking the status of the kernel and device drivers, and ensuring that all critical services are functioning correctly.\\n\\nStep 5: Verify the Results - Once the update has been applied to all nodes in the cluster, verify that the update was successful. This may involve running diagnostic tests to validate the functionality of the cluster, checking the logs to ensure that there were no errors during the update process, and monitoring the performance of the cluster to ensure that it's operating within expected parameters.\\n\\nStep 6: Post-Update Validation - After completing the update, run additional validation checks to ensure that the cluster is operating correctly. This may involve verifying that all services are running, checking the status of the storage subsystem, and ensuring that network connectivity is established between nodes.\\n\\nBy following these steps, organizations can effectively implement cluster-aware updates for their VxRail clusters, ensuring minimal disruption to operations while maintaining a highly available and optimized IT infrastructure.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain] [13.44s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"  Certainly! Here's a detailed explanation of the process involved in conducting a cluster-aware update for VxRail:\\n\\nStep 1: Preparation - Before starting the update process, it's essential to ensure that the cluster is properly configured and all necessary prerequisites are met. This includes verifying that the latest software versions are installed, validating the integrity of the storage subsystem, and confirming that the network infrastructure is stable and capable of handling the update process.\\n\\nStep 2: Identify Nodes to be Upgraded - Use the VxRail Manager interface to identify the nodes that need to be upgraded. This involves selecting the appropriate criteria for determining which nodes should be included in the update process. For instance, you might choose to upgrade nodes based on factors such as CPU age, memory usage, or disk usage.\\n\\nStep 3: Create an Update Plan - After identifying the nodes to be upgraded, create an update plan that outlines the steps involved in the upgrade process. This plan should include the sequence of actions to be taken, the estimated duration for each action, and any potential risks or issues that could arise during the update.\\n\\nStep 4: Apply the Update - With the update plan in place, apply the updates to the identified nodes one at a time. During this phase, the VxRail Manager will perform various checks to ensure that the update is applied correctly and without disrupting the operation of the cluster. These checks may include verifying the consistency of the file systems, checking the status of the kernel and device drivers, and ensuring that all critical services are functioning correctly.\\n\\nStep 5: Verify the Results - Once the update has been applied to all nodes in the cluster, verify that the update was successful. This may involve running diagnostic tests to validate the functionality of the cluster, checking the logs to ensure that there were no errors during the update process, and monitoring the performance of the cluster to ensure that it's operating within expected parameters.\\n\\nStep 6: Post-Update Validation - After completing the update, run additional validation checks to ensure that the cluster is operating correctly. This may involve verifying that all services are running, checking the status of the storage subsystem, and ensuring that network connectivity is established between nodes.\\n\\nBy following these steps, organizations can effectively implement cluster-aware updates for their VxRail clusters, ensuring minimal disruption to operations while maintaining a highly available and optimized IT infrastructure.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain] [13.46s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "============================================\n",
      "===============Source Documents============\n",
      "============================================\n",
      "{'page': 19, 'source': 'pdfs-dell-infohub/h10588-isilon-data-availability-protection-wp.pdf'}\n",
      "{'page': 62, 'source': 'pdfs-dell-infohub/h19672_deploying_dell_powerflex_with_vmware_tanzu .pdf'}\n",
      "============================================\n",
      "============================================\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"[INST] <<SYS>>You are a technical research assistant, you answer only in English language. Your audience appreciates technical details in your answer.  Using the provided summaries of context and the chat history provided, please respond in a helpful, concise manner.<</SYS>>\\n\\n Summaries: Content: Contents  \\n \\n3 Dell PowerFlex: Maintenance Modes  \\nOverview and Basic Configuration  \\n Contents  \\nExecutive summary  ................................ ................................ ................................ .......................  4 \\nOverview  ................................ ................................ ................................ ................................ ........  5\\nSource: pdfs-dell-infohub/h18794-dell-powerflex-maintenance-modes.pdf\\n\\nContent: We value your feedback \\nDell Technologies and the authors of this document welcome your feedback on the solution and the solution documentation. Contact the Dell Technologies Solutions team by \\nemail\\n. \\nAuthors : Drew Tonnesen, Dell Technologies PowerFlex Engineering  \\nContributors : Dell Technologies Solution Information Development & Design team\\nSource: pdfs-dell-infohub/h19672_deploying_dell_powerflex_with_vmware_tanzu .pdf\\n\\nContent: Contents  \\n \\n3 Dell PowerFlex: Introduction to Replication  \\nOverview and Basic Configuration  \\n Contents  \\nExecutive summary ........................................................................................................................ 4 \\nIntroduction ..................................................................................................................................... 5\\nSource: pdfs-dell-infohub/h18391-powerflex-introduction-to-replication-wp.pdf\\n\\nContent: Dell PowerFlex  API version  2.6, 3 .1, 3.5, 3.6\\nSource: pdfs-dell-infohub/Splunk_UserGuide_FinalDraft.pdf \\n\\n  Chat History: [HumanMessage(content='Provide a summary on VXrail cluster aware updating'), AIMessage(content=\\\"  Sure! Based on the provided content and chat history, here's a summary of VxRail cluster aware updating:\\\\n\\\\nVxRail provides automated end-to-end lifecycle management for modernizing data centers across edge, core, and cloud environments. As part of its feature set, VxRail offers cluster aware updating, which enables customers to update their entire cluster simultaneously without downtime or manual intervention. This feature streamlines the updating process, reducing complexity and improving overall efficiency.\\\\n\\\\nCluster aware updating in VxRail works by leveraging advanced algorithms that monitor the health of each node in the cluster and determine the optimal time for updates. Once the algorithm identifies the best window for updating, VxRail automatically applies the necessary changes to all nodes in the cluster, ensuring consistent configuration across the environment.\\\\n\\\\nBy utilizing this feature, organizations can reduce the risk of human error during updates, minimize downtime, and improve overall system stability. Cluster aware updating also enables organizations to quickly adapt to changing business needs and take advantage of new features and capabilities as they become available.\\\"), HumanMessage(content='document the process of a cluster aware upate for VXrail'), AIMessage(content=\\\"  Certainly! Here's a detailed explanation of the process involved in conducting a cluster-aware update for VxRail:\\\\n\\\\nStep 1: Preparation - Before starting the update process, it's essential to ensure that the cluster is properly configured and all necessary prerequisites are met. This includes verifying that the latest software versions are installed, validating the integrity of the storage subsystem, and confirming that the network infrastructure is stable and capable of handling the update process.\\\\n\\\\nStep 2: Identify Nodes to be Upgraded - Use the VxRail Manager interface to identify the nodes that need to be upgraded. This involves selecting the appropriate criteria for determining which nodes should be included in the update process. For instance, you might choose to upgrade nodes based on factors such as CPU age, memory usage, or disk usage.\\\\n\\\\nStep 3: Create an Update Plan - After identifying the nodes to be upgraded, create an update plan that outlines the steps involved in the upgrade process. This plan should include the sequence of actions to be taken, the estimated duration for each action, and any potential risks or issues that could arise during the update.\\\\n\\\\nStep 4: Apply the Update - With the update plan in place, apply the updates to the identified nodes one at a time. During this phase, the VxRail Manager will perform various checks to ensure that the update is applied correctly and without disrupting the operation of the cluster. These checks may include verifying the consistency of the file systems, checking the status of the kernel and device drivers, and ensuring that all critical services are functioning correctly.\\\\n\\\\nStep 5: Verify the Results - Once the update has been applied to all nodes in the cluster, verify that the update was successful. This may involve running diagnostic tests to validate the functionality of the cluster, checking the logs to ensure that there were no errors during the update process, and monitoring the performance of the cluster to ensure that it's operating within expected parameters.\\\\n\\\\nStep 6: Post-Update Validation - After completing the update, run additional validation checks to ensure that the cluster is operating correctly. This may involve verifying that all services are running, checking the status of the storage subsystem, and ensuring that network connectivity is established between nodes.\\\\n\\\\nBy following these steps, organizations can effectively implement cluster-aware updates for their VxRail clusters, ensuring minimal disruption to operations while maintaining a highly available and optimized IT infrastructure.\\\")] \\n\\n  Question: Would you please write a professional email response to John explaining the benefits of Dell Powerflex. Please be concise and in paragraph form, no lists or bullet points.\\n\\n[/INST]\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:HuggingFacePipeline] [12.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"  Subject: Benefits of Dell PowerFlex for Modern Data Centers\\n\\nDear John,\\n\\nI hope this email finds you well. I wanted to share with you the key benefits of Dell PowerFlex, a cutting-edge technology designed to optimize data center operations. As you know, power flexibility is crucial in today's fast-paced digital landscape, where organizations must constantly adapt to changing business demands. That's where Dell PowerFlex shines, providing numerous advantages that can help your organization stay ahead of the curve.\\n\\nFirstly, Dell PowerFlex allows for seamless scalability, enabling you to easily add or remove resources as needed. This means you can scale your data center capacity according to demand, avoiding unnecessary investments in unused hardware. Additionally, PowerFlex supports both traditional and containerized workloads, allowing you to consolidate multiple applications onto fewer servers, resulting in significant cost savings.\\n\\nSecondly, Dell PowerFlex offers improved resource utilization through intelligent placement of virtual machines (VMs). By optimally allocating VMs across different hosts, you can maximize resource utilization, leading to increased productivity and reduced costs. Furthermore, PowerFlex integrates with other Dell technologies like VMware vRealize Automation, enabling centralized management of your entire hybrid cloud environment.\\n\\nLastly, Dell PowerFlex provides robust security features to protect your sensitive data. With built-in encryption and secure boot capabilities, you can rest assured that your data remains safe from unauthorized access. Moreover, PowerFlex supports multi-tenancy, allowing you to efficiently manage diverse workloads and users under a single platform.\\n\\nIn conclusion, Dell PowerFlex represents a powerful tool for modern data centers seeking greater agility, efficiency, and security. Its ability to accommodate evolving business requirements, optimize resource allocation, and safeguard sensitive data make it an ideal choice for organizations looking to future-proof their IT infrastructure. If you have any questions or would like further information, please don't hesitate to contact me.\\n\\nBest regards,\\n\\n[Your Name]\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [12.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"  Subject: Benefits of Dell PowerFlex for Modern Data Centers\\n\\nDear John,\\n\\nI hope this email finds you well. I wanted to share with you the key benefits of Dell PowerFlex, a cutting-edge technology designed to optimize data center operations. As you know, power flexibility is crucial in today's fast-paced digital landscape, where organizations must constantly adapt to changing business demands. That's where Dell PowerFlex shines, providing numerous advantages that can help your organization stay ahead of the curve.\\n\\nFirstly, Dell PowerFlex allows for seamless scalability, enabling you to easily add or remove resources as needed. This means you can scale your data center capacity according to demand, avoiding unnecessary investments in unused hardware. Additionally, PowerFlex supports both traditional and containerized workloads, allowing you to consolidate multiple applications onto fewer servers, resulting in significant cost savings.\\n\\nSecondly, Dell PowerFlex offers improved resource utilization through intelligent placement of virtual machines (VMs). By optimally allocating VMs across different hosts, you can maximize resource utilization, leading to increased productivity and reduced costs. Furthermore, PowerFlex integrates with other Dell technologies like VMware vRealize Automation, enabling centralized management of your entire hybrid cloud environment.\\n\\nLastly, Dell PowerFlex provides robust security features to protect your sensitive data. With built-in encryption and secure boot capabilities, you can rest assured that your data remains safe from unauthorized access. Moreover, PowerFlex supports multi-tenancy, allowing you to efficiently manage diverse workloads and users under a single platform.\\n\\nIn conclusion, Dell PowerFlex represents a powerful tool for modern data centers seeking greater agility, efficiency, and security. Its ability to accommodate evolving business requirements, optimize resource allocation, and safeguard sensitive data make it an ideal choice for organizations looking to future-proof their IT infrastructure. If you have any questions or would like further information, please don't hesitate to contact me.\\n\\nBest regards,\\n\\n[Your Name]\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain > 3:chain:StuffDocumentsChain] [12.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"  Subject: Benefits of Dell PowerFlex for Modern Data Centers\\n\\nDear John,\\n\\nI hope this email finds you well. I wanted to share with you the key benefits of Dell PowerFlex, a cutting-edge technology designed to optimize data center operations. As you know, power flexibility is crucial in today's fast-paced digital landscape, where organizations must constantly adapt to changing business demands. That's where Dell PowerFlex shines, providing numerous advantages that can help your organization stay ahead of the curve.\\n\\nFirstly, Dell PowerFlex allows for seamless scalability, enabling you to easily add or remove resources as needed. This means you can scale your data center capacity according to demand, avoiding unnecessary investments in unused hardware. Additionally, PowerFlex supports both traditional and containerized workloads, allowing you to consolidate multiple applications onto fewer servers, resulting in significant cost savings.\\n\\nSecondly, Dell PowerFlex offers improved resource utilization through intelligent placement of virtual machines (VMs). By optimally allocating VMs across different hosts, you can maximize resource utilization, leading to increased productivity and reduced costs. Furthermore, PowerFlex integrates with other Dell technologies like VMware vRealize Automation, enabling centralized management of your entire hybrid cloud environment.\\n\\nLastly, Dell PowerFlex provides robust security features to protect your sensitive data. With built-in encryption and secure boot capabilities, you can rest assured that your data remains safe from unauthorized access. Moreover, PowerFlex supports multi-tenancy, allowing you to efficiently manage diverse workloads and users under a single platform.\\n\\nIn conclusion, Dell PowerFlex represents a powerful tool for modern data centers seeking greater agility, efficiency, and security. Its ability to accommodate evolving business requirements, optimize resource allocation, and safeguard sensitive data make it an ideal choice for organizations looking to future-proof their IT infrastructure. If you have any questions or would like further information, please don't hesitate to contact me.\\n\\nBest regards,\\n\\n[Your Name]\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQAWithSourcesChain] [12.05s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "============================================\n",
      "===============Source Documents============\n",
      "============================================\n",
      "{'page': 2, 'source': 'pdfs-dell-infohub/h18794-dell-powerflex-maintenance-modes.pdf'}\n",
      "{'page': 75, 'source': 'pdfs-dell-infohub/h19672_deploying_dell_powerflex_with_vmware_tanzu .pdf'}\n",
      "============================================\n",
      "============================================\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "chat_interface = gr.ChatInterface(\n",
    "    \n",
    "    ### call the main process function above\n",
    "    \n",
    "    fn=process_input, \n",
    "\n",
    "    ### format the dialogue box, add company avatar image\n",
    "    \n",
    "    chatbot = gr.Chatbot(\n",
    "        bubble_full_width=False,\n",
    "        avatar_images=(None, (os.path.join(os.path.dirname(\"__file__\"), \"images/dell-logo-sm.jpg\"))),\n",
    "    ),\n",
    "\n",
    "    \n",
    "    additional_inputs=[\n",
    "        \n",
    "        gr.Textbox(label=\"Persona and role for system prompt:\", \n",
    "                   lines=3, \n",
    "                   value=\"\"\"You are a technical research assistant, you answer only in English language. Your audience appreciates technical details in your answer.  Using the provided summaries of context and the chat history provided, please respond in a helpful, concise manner.\"\"\"\n",
    "                  ),\n",
    "        \n",
    "        gr.Slider(\n",
    "            label=\"Max new words (tokens)\",\n",
    "            minimum=1,\n",
    "            maximum=MAX_MAX_NEW_TOKENS,\n",
    "            step=1,\n",
    "            value=DEFAULT_MAX_NEW_TOKENS,\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"Creativity (Temperature), higher is more creative, lower is less creative:\",\n",
    "            minimum=0.1,\n",
    "            maximum=2.0,\n",
    "            step=0.1,\n",
    "            value=0.6,\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"Top probable tokens (Nucleus sampling top-p), affects creativity:\",\n",
    "            minimum=0.05,\n",
    "            maximum=1.0,\n",
    "            step=0.05,\n",
    "            value=0.9,\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"Number of top tokens to choose from (Top-k):\",\n",
    "            minimum=1,\n",
    "            maximum=100,\n",
    "            step=1,\n",
    "            value=50,\n",
    "        ),\n",
    "        gr.Slider(\n",
    "            label=\"Repetition penalty:\",\n",
    "            minimum=1.0,\n",
    "            maximum=1.99,\n",
    "            step=0.05,\n",
    "            value=1.2,\n",
    "        ),\n",
    "    ],\n",
    "    \n",
    "    stop_btn=None,\n",
    "    \n",
    "    examples=[\n",
    "        [\"Can you give me a detailed summary of the document PDFs-Dell-Infohub/h19642-Introduction-to-Apex-File-Storage-for-AWS.pdf?\"],\n",
    "        [\"Please summarize 3 Dell Technologies solutions for the Telecom industry.\"],\n",
    "        [\"How does Dell APEX block storage support multiple availability zones?\"],\n",
    "        [\"Would you please write a professional email response to John explaining the benefits of Dell Powerflex. Please be concise and in paragraph form, no lists or bullet points.\"],\n",
    "        [\"Create a new advertisement for Dell Technologies PowerEdge servers.  Please include an interesting headline and product description.  You want to persuade the target audience of IT decision makers to purchase PowerEdge servers. Include a section at the end titled Call to Action, listing next steps the readers should take.\"],\n",
    "        [\"What's the sentiment of this phrase 'I had fun at Disneyland'?\"],\n",
    "\n",
    "    ],\n",
    "\n",
    ")\n",
    "\n",
    "###  SET GRADIO INTERFACE THEME (https://www.gradio.app/guides/theming-guide)\n",
    "\n",
    "#theme = gr.themes.Soft()\n",
    "#theme = gr.themes.Glass()\n",
    "theme = gr.themes.Default()\n",
    "\n",
    "\n",
    "### set width and margins in local css file\n",
    "### set Title in a markdown object at the top, then render the chat interface\n",
    "\n",
    "with gr.Blocks(theme=theme, css=\"style.css\") as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Digital Assistant Chatbot\n",
    "    ##### - If you get a highly unusual answer, try again with the 'retry' button\n",
    "    ##### - Click advanced settings to adjust the system prompt and persona\n",
    "    ##### - Prompt engineering is key, you will get better formed answers with better prompts\n",
    "    \"\"\")\n",
    "    \n",
    "    chat_interface.render()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.queue(max_size=1)  ## sets up websockets for bidirectional comms and no timeouts, set a max number users in queue\n",
    "    demo.launch(share=False, debug=True, server_name=\"172.16.6.3\", server_port=7861, allowed_paths=[\"images/dell-logo-sm.jpg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905fc4e-627e-4e2e-aa3b-7731f9bc3d1c",
   "metadata": {},
   "source": [
    "### Inspiration code:\n",
    "\n",
    "https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e49b85-5d9c-40ef-82cc-6c7f578695be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
